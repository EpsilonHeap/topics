{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### License\n",
    "Licensed under the BSD 3-Clause License (the \"License\");"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BSD 3-Clause License\n",
    "\n",
    "Copyright (c) 2017, Pytorch contributors\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without\n",
    "modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation\n",
    "  and/or other materials provided with the distribution.\n",
    "\n",
    "* Neither the name of the copyright holder nor the names of its\n",
    "  contributors may be used to endorse or promote products derived from\n",
    "  this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper ['Fast Sparse Regression and Classification' (2008)](http://statweb.stanford.edu/~jhf/ftp/GPSpaper.pdf), [Jerome Friedman](https://statweb.stanford.edu/~jhf/) introduces the generalized path seeking (GPS) algorithm to directly construct, sequentially, a path in parameter space that approximates that for a given penalty $P(a)$ on the coffefficents $a$ of an associated regression model. This Jupyter notebook is an implementation of GPS that takes advantage of the 'autograd' facility provided by many machine learning frameworks for calculating gradients. [PyTorch (1.0.1)](https://pytorch.org/) will be used in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple model and loss function to demonstrate how useful autograd will be for implementing GPS. $a$ is a vector of coefficients of the regression model and is exposed at the toplevel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9\n",
    "a = torch.zeros(N,requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "def Fmodel(a, x):\n",
    "    \"\"\" a is the coefficient vector of a linear regression model\n",
    "        a[0] is the constant term\n",
    "        x is a matrix of data where each row is an observation \"\"\"\n",
    "    return (x @ a[1:]) + a[0]\n",
    "\n",
    "def mse(t1,t2):\n",
    "    \"\"\" mean square error \"\"\"\n",
    "    diff = t1-t2\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a concrete example, we will use data from [Stamey et al (1989)](https://www.ncbi.nlm.nih.gov/pubmed/2468795) that can be accessed online at [Robert Tibshirani's](https://statweb.stanford.edu/~tibs) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45',\n",
      "       'lpsa', 'train'],\n",
      "      dtype='object')\n",
      "tensor([[-0.5798,  2.7695, 50.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [-0.9943,  3.3196, 58.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [-0.5108,  2.6912, 74.0000, -1.3863,  0.0000, -1.3863,  7.0000, 20.0000],\n",
      "        [-1.2040,  3.2828, 58.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [ 0.7514,  3.4324, 62.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [-1.0498,  3.2288, 50.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [ 0.7372,  3.4735, 64.0000,  0.6152,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [ 0.6931,  3.5395, 58.0000,  1.5369,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [-0.7765,  3.5395, 47.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000],\n",
      "        [ 0.2231,  3.2445, 63.0000, -1.3863,  0.0000, -1.3863,  6.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pdata = pd.read_csv(\"http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data\",\n",
    "                    index_col=0,sep='\\t')\n",
    "# lpsa values are the y[i]'s that we want to predict\n",
    "lpsa = torch.from_numpy(pdata.lpsa.values)\n",
    "print(pdata.columns)\n",
    "xvals = torch.from_numpy(pdata[['lcavol','lweight','age','lbph','svi','lcp','gleason','pgg45']].values)\n",
    "print(xvals[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Fmodel(a, xvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4308, -0.1625, -0.1625, -0.1625,  0.3716,  0.7655,  0.7655,  0.8544,\n",
       "         1.0473,  1.0473], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpsa[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.4611, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse(preds,lpsa)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch keeps track of the mathematical operations performed on $a$ and will automatically calculate the gradient using reverse-mode differentiation that is often used for back-propagation in neural nets. In PyTorch, invoking the backword() method on a scalar tensor will automatically calculate the gradient. Note that gradients cumulate and will need to be zeroed out where appropriate for the calculation at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([  -4.9568,   -8.6696,  -18.4120, -319.4542,   -1.0935,   -1.6087,\n",
      "          -0.8643,  -34.0798, -148.0683], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(a)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach to updating the coefficients and minimize the loss is to iteratively move along the direction of the gradient. We will use this idea later to address a minor issue with the GPS algorithm as stated in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    preds = Fmodel(a, xvals)\n",
    "    loss = mse(preds, lpsa)\n",
    "    loss.backward()\n",
    "    # no_grad() context because we do not want to calcualte but update a\n",
    "    with torch.no_grad():\n",
    "        a -= a.grad * 1e-5\n",
    "        a.grad.zero_()\n",
    "a_ref = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8563, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4125, 1.5940, 2.2870, 1.5660, 1.9234, 1.3732, 2.0223, 1.8837, 1.3424,\n",
      "        1.8751, 1.9471, 1.7544, 2.4407, 2.2096, 2.0001, 2.1117, 2.4514, 2.3558,\n",
      "        1.2002, 2.1494, 1.8940, 2.5385, 1.6929, 2.9630, 2.1405, 2.1942, 2.7896,\n",
      "        2.2424, 3.0851, 2.4215, 2.0914, 2.0184, 2.2699, 1.6132, 1.8863, 2.2407,\n",
      "        2.7582, 2.0804, 3.0699, 1.9769, 2.7702, 2.3134, 2.0606, 2.2945, 2.5000,\n",
      "        2.2440, 4.1743, 2.7475, 1.5530, 2.3040, 2.7018, 2.2052, 2.8866, 3.0069,\n",
      "        2.2331, 2.3985, 1.7394, 1.6258, 2.4212, 2.4656, 2.3084, 2.9030, 3.7387,\n",
      "        3.2277, 2.1504, 2.3739, 3.2891, 2.6829, 1.9986, 2.5101, 2.9001, 2.7291,\n",
      "        2.5677, 3.2882, 2.9128, 3.2606, 3.2614, 2.8288, 3.4287, 2.9003, 2.7113,\n",
      "        2.9801, 3.1047, 3.3660, 2.5567, 3.2542, 2.0618, 2.5395, 3.2797, 3.4611,\n",
      "        2.4237, 2.4141, 3.2438, 2.5904, 2.3703, 3.5405, 3.0644],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4308, -0.1625, -0.1625, -0.1625,  0.3716,  0.7655,  0.7655,  0.8544,\n",
      "         1.0473,  1.0473,  1.2669,  1.2669,  1.2669,  1.3481,  1.3987,  1.4469,\n",
      "         1.4702,  1.4929,  1.5581,  1.5994,  1.6390,  1.6582,  1.6956,  1.7138,\n",
      "         1.7317,  1.7664,  1.8001,  1.8165,  1.8485,  1.8946,  1.9242,  2.0082,\n",
      "         2.0082,  2.0215,  2.0477,  2.0857,  2.1576,  2.1917,  2.2138,  2.2773,\n",
      "         2.2976,  2.3076,  2.3273,  2.3749,  2.5217,  2.5533,  2.5688,  2.5688,\n",
      "         2.5915,  2.5915,  2.6568,  2.6776,  2.6844,  2.6912,  2.7047,  2.7180,\n",
      "         2.7881,  2.7942,  2.8064,  2.8124,  2.8420,  2.8536,  2.8536,  2.8820,\n",
      "         2.8820,  2.8876,  2.9205,  2.9627,  2.9627,  2.9730,  3.0131,  3.0374,\n",
      "         3.0564,  3.0750,  3.2753,  3.3375,  3.3928,  3.4356,  3.4579,  3.5130,\n",
      "         3.5160,  3.5308,  3.5653,  3.5709,  3.5877,  3.6310,  3.6801,  3.7124,\n",
      "         3.9843,  3.9936,  4.0298,  4.1296,  4.3851,  4.6844,  5.1431,  5.4775,\n",
      "         5.5829], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(lpsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central to the implementation of GPS are equations (24), (25), and (26) defined on page 6 of the article - reproduced below. Equations (24) and (25) captures the gradient of empirical 'risk' $\\hat{R}(a)$ and the penalty $P(a)$ used to regularized the model, respectively. Both are directional vectors in the parameter space of a regression problem. While (24) is directly depedent on the model and data, (25) has a more 'universal' nature in that they are gradients of a penalty with respect to parameters -- which typically have a form applicable across models. Note that $\\nu$ is a parameterization of the steps size in parameter space, and the 'hat' symbol e.g. ($\\hat{R}$ and $\\hat{a}$) signifies empirical quantities that are explicit dependent on the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "g_{j}(\\nu) & = & - & \n",
    "\\left[\\frac{\\partial \\hat{R}(a)}{\\partial a_{j}}\\right]_{a=\\hat{a}(\\nu)} & \\hspace{1in} (24) \\\\\n",
    "p_{j}(\\nu) & = & & \n",
    "\\left[\\frac{\\partial P(a)}{\\partial \\left| a_{j} \\right|} \\right]_{a=\\hat{a}(\\nu)} & \\hspace{1in} (25) \\\\\n",
    "\\lambda_{j}(\\nu) & = & & \n",
    "\\frac{g_{j}(\\nu)}{p_{j}(\\nu)} & \\hspace{1in} (26)\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before putting together the whole algorithm, each piece will be demonstrated separately. Without going into details at this point (see Section 2.3 of the paper), $a$ will be reset to zero and slightly pushed along the negative gradient as a starting point for this demonstration. The difficulty with zero is not surprising when dealing with gradients of absolute values evaluate at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9\n",
    "a = torch.zeros(N,requires_grad=True, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(Fmodel(a, xvals), lpsa)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    a -= a.grad * 1e-5\n",
    "    a.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Compute \\{\\lambda_{j}(\\nu)\\}^{n}_{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9568e-05, 8.6696e-05, 1.8412e-04, 3.1945e-03, 1.0935e-05, 1.6087e-05,\n",
      "        8.6427e-06, 3.4080e-04, 1.4807e-03], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor(6.2674, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.2558e-05, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
      "tensor([9.9135e-05, 1.7339e-04, 3.6824e-04, 6.3891e-03, 2.1870e-05, 3.2174e-05,\n",
      "        1.7285e-05, 6.8160e-04, 2.9614e-03], dtype=torch.float64)\n",
      "tensor([  4.4702,   7.9575,  16.6355, 287.8595,   1.0111,   1.4853,   0.8695,\n",
      "         30.7401, 133.4941], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "R = mse(Fmodel(a, xvals), lpsa);R.backward(); g = -a.grad; a.grad.zero_() #(24)\n",
    "print(R)\n",
    "#P = abs(a).pow(1/2).sum(); P.backward(); p = abs(a.grad); a.grad.zero_() #(25)\n",
    "P = abs(a).pow(2).sum(); P.backward(); p = abs(a.grad); a.grad.zero_() #(25)\n",
    "print(P)\n",
    "l = g/p #(26)\n",
    "print(p)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ S = \\{ j \\, | \\, \\lambda_{j}(\\nu) * \\hat{a}_{j}(\\nu) < 0 \\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([45092.3164, 45893.0302, 45175.6898, 45054.8953, 46234.0950, 46164.1531,\n",
      "        50303.5029, 45100.0898, 45078.5758], dtype=torch.float64)\n",
      "tensor([4.9568e-05, 8.6696e-05, 1.8412e-04, 3.1945e-03, 1.0935e-05, 1.6087e-05,\n",
      "        8.6427e-06, 3.4080e-04, 1.4807e-03], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# use element wise multiplication and less than 0 predicate\n",
    "# to find elements with corresponding opposite sign\n",
    "S = l*a < 0\n",
    "print(l)\n",
    "print(a)\n",
    "print (S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray}\n",
    "if \\; (S = empty) \\hspace{5pt} & j^{*} & = arg\\,max_{j} & | \\lambda_{j}(\\nu) | \\\\\n",
    "else \\hspace{5pt} & j^{*} & = arg\\,max_{j \\in S} & | \\lambda_{j}(\\nu) | \n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50303.5029, dtype=torch.float64) tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# need to maintain idx location, i.e. need to keep tensor shape the same throughout\n",
    "# torch.max() finds max element and respective index\n",
    "if S.sum() > 0: # check for elements in set\n",
    "    # non empty case (order different than stated algorithm)\n",
    "    # S.double() for matching element types needed by PyTorch\n",
    "    # element wise mult to zero out elements not meeting predicate condition\n",
    "    # done this way to make sure idx refer to corresponding element\n",
    "    val,idx = torch.max(S.double() * l.abs(), 0)\n",
    "else:\n",
    "    # empty case\n",
    "    val,idx = torch.max(l.abs(), 0)\n",
    "print(val,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{a}_{j^{*}}(\\nu + \\Delta \\nu) = \\hat{a}_{j^{*}}(\\nu) + \\Delta \\nu * sign(\\lambda_{j^{*}}(\\nu)) \\\\\n",
    " \\{ \\hat{a}_{j}(\\nu + \\Delta \\nu) = \\hat{a}_{j}(\\nu) \\}_{j \\ne j^{*}} $$\n",
    "$$ \\nu \\leftarrow \\nu + \\Delta \\nu $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6) tensor(8.6427e-06, dtype=torch.float64, grad_fn=<SelectBackward>) tensor(50303.5029, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# update single component, a[idx], with new value\n",
    "# here are the values at play for this iteration\n",
    "print(idx, a[idx], l[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a[idx] compoment is updated with a new value, the rest remain unchanged. The code would then be something along the line of:\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    a[idx] += del_nu * torch.sign(l[idx])\n",
    "    a.grad.zero_()\n",
    "```\n",
    "Choosing $\\Delta \\nu$ is an implementation decision.\n",
    "Note that $\\Delta \\nu$ is an implied change in the parameterized path of $a(\\nu)$ that would bring about a change of $\\Delta a$. Since $sign(\\lambda_{j^{*}}(\\nu))$ contributes only the sign of the change, $\\Delta \\nu$ is effectively the magnitude of $\\Delta a$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 9.4 of the paper suggests one approach to setting the step size: chose $\\Delta \\nu$ to reduce the empirical risk $\\hat{R}(\\hat{a})$ by a fixed fraction $\\epsilon$.\n",
    "\n",
    "$$ \\frac{\\left [ \\hat{R}(\\hat{a}(\\nu)) - \\hat{R}(\\hat{a}(\\nu + \\Delta \\nu)) \\right]}\n",
    "{\\hat{R}(\\hat{a}(\\nu))} = \\epsilon $$\n",
    "\n",
    "The algorithm updates one component $a_{j^{*}}$ at a time. An approximation for $\\epsilon$ is then\n",
    "\n",
    "$$ \\left | \\frac{g_{j^{*}}(\\nu) * \\Delta a_{j^{*}}}{\\hat{R}(a(\\nu))_{a=\\hat{a}(\\nu)}} \\right | \\approx \\epsilon $$\n",
    "\n",
    "With a choice of $\\epsilon$ = 0.01,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0084, dtype=torch.float64, grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    del_nu = 0.01 * (R / g[idx]).abs()\n",
    "    a[idx] += del_nu * torch.sign(l[idx])\n",
    "    R_post = mse(Fmodel(a, xvals), lpsa)\n",
    "    a.grad.zero_()\n",
    "    \n",
    "# should be 'close' to 0.01\n",
    "print(1-(R_post/R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPS algorithm with all the pieces composed together.\n",
    "\n",
    "Line numbering are diffent from the paper because the breakdown above was composed as units that better match this description.\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "1 & Initialize: \\nu = 0; \\{\\hat{a}_{j}(0) = 0\\}_{1}^{n} \\\\\n",
    "2 & Loop \\; \\{ \\\\\n",
    "3 & \\hspace{10pt} Compute \\{\\lambda_{j}(\\nu)\\}^{n}_{1} \\\\\n",
    "4 & \\hspace{10pt} S = \\{ j \\, | \\, \\lambda_{j}(\\nu) * \\hat{a}_{j}(\\nu) < 0 \\} \\\\\n",
    "5 & \\hspace{10pt} \\begin{eqnarray}\n",
    "if \\; (S = empty) \\hspace{5pt} & j^{*} & = arg\\,max_{j} & | \\lambda_{j}(\\nu) | \\\\\n",
    "else \\hspace{10pt} & j^{*} & = arg\\,max_{j \\in S} & | \\lambda_{j}(\\nu) |\n",
    "\\end{eqnarray} \\\\\n",
    "6 & \\hspace{10pt} \\hat{a}_{j^{*}}(\\nu + \\Delta \\nu) = \\hat{a}_{j^{*}}(\\nu) + \\Delta \\nu * sign(\\lambda_{j^{*}}(\\nu)); \\{ \\hat{a}_{j}(\\nu + \\Delta \\nu) = \\hat{a}_{j}(\\nu) \\}_{j \\ne j^{*}} \\\\\n",
    "7 & \\hspace{10pt} \\nu \\leftarrow \\nu + \\Delta \\nu \\\\\n",
    "8 & \\} \\; Until \\; \\lambda(\\nu) = 0\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(6.2674, dtype=torch.float64) tensor(0.0054, dtype=torch.float64)\n",
      "10 tensor(5.6699, dtype=torch.float64) tensor(0.0075, dtype=torch.float64)\n",
      "20 tensor(5.1295, dtype=torch.float64) tensor(0.0096, dtype=torch.float64)\n",
      "30 tensor(4.6406, dtype=torch.float64) tensor(0.0116, dtype=torch.float64)\n",
      "40 tensor(4.1983, dtype=torch.float64) tensor(0.0135, dtype=torch.float64)\n",
      "50 tensor(3.7983, dtype=torch.float64) tensor(0.0154, dtype=torch.float64)\n",
      "60 tensor(3.4364, dtype=torch.float64) tensor(0.0172, dtype=torch.float64)\n",
      "70 tensor(3.1091, dtype=torch.float64) tensor(0.0190, dtype=torch.float64)\n",
      "80 tensor(2.8131, dtype=torch.float64) tensor(0.0208, dtype=torch.float64)\n",
      "90 tensor(2.5453, dtype=torch.float64) tensor(0.0225, dtype=torch.float64)\n",
      "100 tensor(2.3031, dtype=torch.float64) tensor(0.0243, dtype=torch.float64)\n",
      "110 tensor(2.0841, dtype=torch.float64) tensor(0.0260, dtype=torch.float64)\n",
      "120 tensor(1.8861, dtype=torch.float64) tensor(0.0278, dtype=torch.float64)\n",
      "130 tensor(1.7072, dtype=torch.float64) tensor(0.0297, dtype=torch.float64)\n",
      "140 tensor(1.5457, dtype=torch.float64) tensor(0.0318, dtype=torch.float64)\n",
      "150 tensor(1.4003, dtype=torch.float64) tensor(0.0343, dtype=torch.float64)\n",
      "160 tensor(1.2698, dtype=torch.float64) tensor(0.0378, dtype=torch.float64)\n",
      "170 tensor(1.1522, dtype=torch.float64) tensor(0.0432, dtype=torch.float64)\n",
      "180 tensor(1.9122, dtype=torch.float64) tensor(0.0344, dtype=torch.float64)\n",
      "190 tensor(1.7304, dtype=torch.float64) tensor(0.0360, dtype=torch.float64)\n",
      "200 tensor(1.5662, dtype=torch.float64) tensor(0.0378, dtype=torch.float64)\n",
      "210 tensor(1.4178, dtype=torch.float64) tensor(0.0397, dtype=torch.float64)\n",
      "220 tensor(1.2841, dtype=torch.float64) tensor(0.0418, dtype=torch.float64)\n",
      "230 tensor(1.1645, dtype=torch.float64) tensor(0.0446, dtype=torch.float64)\n",
      "240 tensor(1.2546, dtype=torch.float64) tensor(0.0424, dtype=torch.float64)\n",
      "250 tensor(1.1390, dtype=torch.float64) tensor(0.0456, dtype=torch.float64)\n",
      "260 tensor(1.6227, dtype=torch.float64) tensor(0.0443, dtype=torch.float64)\n",
      "270 tensor(1.4688, dtype=torch.float64) tensor(0.0461, dtype=torch.float64)\n",
      "280 tensor(1.3299, dtype=torch.float64) tensor(0.0481, dtype=torch.float64)\n",
      "290 tensor(1.2051, dtype=torch.float64) tensor(0.0505, dtype=torch.float64)\n",
      "300 tensor(1.0992, dtype=torch.float64) tensor(0.0550, dtype=torch.float64)\n",
      "310 tensor(7.8044, dtype=torch.float64) tensor(0.0306, dtype=torch.float64)\n",
      "320 tensor(7.0603, dtype=torch.float64) tensor(0.0283, dtype=torch.float64)\n",
      "330 tensor(6.3871, dtype=torch.float64) tensor(0.0261, dtype=torch.float64)\n",
      "340 tensor(5.7782, dtype=torch.float64) tensor(0.0240, dtype=torch.float64)\n",
      "350 tensor(5.2273, dtype=torch.float64) tensor(0.0240, dtype=torch.float64)\n",
      "360 tensor(4.7290, dtype=torch.float64) tensor(0.0260, dtype=torch.float64)\n",
      "370 tensor(4.2783, dtype=torch.float64) tensor(0.0279, dtype=torch.float64)\n",
      "380 tensor(3.8705, dtype=torch.float64) tensor(0.0297, dtype=torch.float64)\n",
      "390 tensor(3.5017, dtype=torch.float64) tensor(0.0315, dtype=torch.float64)\n",
      "400 tensor(3.1681, dtype=torch.float64) tensor(0.0332, dtype=torch.float64)\n",
      "410 tensor(2.8663, dtype=torch.float64) tensor(0.0349, dtype=torch.float64)\n",
      "420 tensor(2.5933, dtype=torch.float64) tensor(0.0366, dtype=torch.float64)\n",
      "430 tensor(2.3464, dtype=torch.float64) tensor(0.0382, dtype=torch.float64)\n",
      "440 tensor(2.1231, dtype=torch.float64) tensor(0.0399, dtype=torch.float64)\n",
      "450 tensor(1.9211, dtype=torch.float64) tensor(0.0415, dtype=torch.float64)\n",
      "460 tensor(1.7385, dtype=torch.float64) tensor(0.0432, dtype=torch.float64)\n",
      "470 tensor(1.5735, dtype=torch.float64) tensor(0.0449, dtype=torch.float64)\n",
      "480 tensor(1.4244, dtype=torch.float64) tensor(0.0467, dtype=torch.float64)\n",
      "490 tensor(1.2899, dtype=torch.float64) tensor(0.0488, dtype=torch.float64)\n",
      "500 tensor(1.1694, dtype=torch.float64) tensor(0.0514, dtype=torch.float64)\n",
      "510 tensor(1.0992, dtype=torch.float64) tensor(0.0562, dtype=torch.float64)\n",
      "520 tensor(1.0995, dtype=torch.float64) tensor(0.0563, dtype=torch.float64)\n",
      "530 tensor(3.5749, dtype=torch.float64) tensor(0.0384, dtype=torch.float64)\n",
      "540 tensor(3.2343, dtype=torch.float64) tensor(0.0401, dtype=torch.float64)\n",
      "550 tensor(2.9261, dtype=torch.float64) tensor(0.0418, dtype=torch.float64)\n",
      "560 tensor(2.6474, dtype=torch.float64) tensor(0.0435, dtype=torch.float64)\n",
      "570 tensor(2.3954, dtype=torch.float64) tensor(0.0451, dtype=torch.float64)\n",
      "580 tensor(2.1674, dtype=torch.float64) tensor(0.0467, dtype=torch.float64)\n",
      "590 tensor(1.9612, dtype=torch.float64) tensor(0.0483, dtype=torch.float64)\n",
      "600 tensor(1.7747, dtype=torch.float64) tensor(0.0500, dtype=torch.float64)\n",
      "610 tensor(1.6062, dtype=torch.float64) tensor(0.0517, dtype=torch.float64)\n",
      "620 tensor(1.4538, dtype=torch.float64) tensor(0.0535, dtype=torch.float64)\n",
      "630 tensor(1.3164, dtype=torch.float64) tensor(0.0554, dtype=torch.float64)\n",
      "640 tensor(1.1928, dtype=torch.float64) tensor(0.0578, dtype=torch.float64)\n",
      "650 tensor(1.0883, dtype=torch.float64) tensor(0.0623, dtype=torch.float64)\n",
      "660 tensor(1.1217, dtype=torch.float64) tensor(0.0658, dtype=torch.float64)\n",
      "670 tensor(6.5881, dtype=torch.float64) tensor(0.0344, dtype=torch.float64)\n",
      "680 tensor(5.9600, dtype=torch.float64) tensor(0.0322, dtype=torch.float64)\n",
      "690 tensor(5.3918, dtype=torch.float64) tensor(0.0306, dtype=torch.float64)\n",
      "700 tensor(4.8778, dtype=torch.float64) tensor(0.0326, dtype=torch.float64)\n",
      "710 tensor(4.4128, dtype=torch.float64) tensor(0.0345, dtype=torch.float64)\n",
      "720 tensor(3.9923, dtype=torch.float64) tensor(0.0364, dtype=torch.float64)\n",
      "730 tensor(3.6118, dtype=torch.float64) tensor(0.0382, dtype=torch.float64)\n",
      "740 tensor(3.2676, dtype=torch.float64) tensor(0.0399, dtype=torch.float64)\n",
      "750 tensor(2.9563, dtype=torch.float64) tensor(0.0416, dtype=torch.float64)\n",
      "760 tensor(2.6748, dtype=torch.float64) tensor(0.0433, dtype=torch.float64)\n",
      "770 tensor(2.4201, dtype=torch.float64) tensor(0.0449, dtype=torch.float64)\n",
      "780 tensor(2.1897, dtype=torch.float64) tensor(0.0466, dtype=torch.float64)\n",
      "790 tensor(1.9814, dtype=torch.float64) tensor(0.0482, dtype=torch.float64)\n",
      "800 tensor(1.7930, dtype=torch.float64) tensor(0.0498, dtype=torch.float64)\n",
      "810 tensor(1.6227, dtype=torch.float64) tensor(0.0515, dtype=torch.float64)\n",
      "820 tensor(1.4688, dtype=torch.float64) tensor(0.0533, dtype=torch.float64)\n",
      "830 tensor(1.3298, dtype=torch.float64) tensor(0.0552, dtype=torch.float64)\n",
      "840 tensor(1.2048, dtype=torch.float64) tensor(0.0575, dtype=torch.float64)\n",
      "850 tensor(1.0961, dtype=torch.float64) tensor(0.0614, dtype=torch.float64)\n",
      "860 tensor(1.3552, dtype=torch.float64) tensor(0.0621, dtype=torch.float64)\n",
      "870 tensor(1.2275, dtype=torch.float64) tensor(0.0642, dtype=torch.float64)\n",
      "880 tensor(1.1139, dtype=torch.float64) tensor(0.0673, dtype=torch.float64)\n",
      "890 tensor(1.0858, dtype=torch.float64) tensor(0.0687, dtype=torch.float64)\n",
      "900 tensor(1.1154, dtype=torch.float64) tensor(0.0672, dtype=torch.float64)\n",
      "910 tensor(1.0876, dtype=torch.float64) tensor(0.0686, dtype=torch.float64)\n",
      "920 tensor(1.2475, dtype=torch.float64) tensor(0.0638, dtype=torch.float64)\n",
      "930 tensor(1.1314, dtype=torch.float64) tensor(0.0666, dtype=torch.float64)\n",
      "940 tensor(11.0544, dtype=torch.float64) tensor(0.0547, dtype=torch.float64)\n",
      "950 tensor(10.0002, dtype=torch.float64) tensor(0.0521, dtype=torch.float64)\n",
      "960 tensor(9.0466, dtype=torch.float64) tensor(0.0495, dtype=torch.float64)\n",
      "970 tensor(8.1840, dtype=torch.float64) tensor(0.0471, dtype=torch.float64)\n",
      "980 tensor(7.4036, dtype=torch.float64) tensor(0.0447, dtype=torch.float64)\n",
      "990 tensor(6.6977, dtype=torch.float64) tensor(0.0425, dtype=torch.float64)\n",
      "1000 tensor(6.0591, dtype=torch.float64) tensor(0.0403, dtype=torch.float64)\n",
      "1010 tensor(5.4814, dtype=torch.float64) tensor(0.0383, dtype=torch.float64)\n",
      "1020 tensor(4.9589, dtype=torch.float64) tensor(0.0396, dtype=torch.float64)\n",
      "1030 tensor(4.4862, dtype=torch.float64) tensor(0.0416, dtype=torch.float64)\n",
      "1040 tensor(4.0586, dtype=torch.float64) tensor(0.0434, dtype=torch.float64)\n",
      "1050 tensor(3.6718, dtype=torch.float64) tensor(0.0452, dtype=torch.float64)\n",
      "1060 tensor(3.3219, dtype=torch.float64) tensor(0.0470, dtype=torch.float64)\n",
      "1070 tensor(3.0054, dtype=torch.float64) tensor(0.0487, dtype=torch.float64)\n",
      "1080 tensor(2.7192, dtype=torch.float64) tensor(0.0503, dtype=torch.float64)\n",
      "1090 tensor(2.4602, dtype=torch.float64) tensor(0.0520, dtype=torch.float64)\n",
      "1100 tensor(2.2260, dtype=torch.float64) tensor(0.0536, dtype=torch.float64)\n",
      "1110 tensor(2.0142, dtype=torch.float64) tensor(0.0552, dtype=torch.float64)\n",
      "1120 tensor(1.8227, dtype=torch.float64) tensor(0.0568, dtype=torch.float64)\n",
      "1130 tensor(1.6495, dtype=torch.float64) tensor(0.0585, dtype=torch.float64)\n",
      "1140 tensor(1.4929, dtype=torch.float64) tensor(0.0602, dtype=torch.float64)\n",
      "1150 tensor(1.3516, dtype=torch.float64) tensor(0.0621, dtype=torch.float64)\n",
      "1160 tensor(1.2242, dtype=torch.float64) tensor(0.0643, dtype=torch.float64)\n",
      "1170 tensor(1.1111, dtype=torch.float64) tensor(0.0674, dtype=torch.float64)\n",
      "1180 tensor(4.4076, dtype=torch.float64) tensor(0.0492, dtype=torch.float64)\n",
      "1190 tensor(3.9875, dtype=torch.float64) tensor(0.0510, dtype=torch.float64)\n",
      "1200 tensor(3.6075, dtype=torch.float64) tensor(0.0528, dtype=torch.float64)\n",
      "1210 tensor(3.2637, dtype=torch.float64) tensor(0.0545, dtype=torch.float64)\n",
      "1220 tensor(2.9528, dtype=torch.float64) tensor(0.0562, dtype=torch.float64)\n",
      "1230 tensor(2.6715, dtype=torch.float64) tensor(0.0579, dtype=torch.float64)\n",
      "1240 tensor(2.4171, dtype=torch.float64) tensor(0.0595, dtype=torch.float64)\n",
      "1250 tensor(2.1871, dtype=torch.float64) tensor(0.0611, dtype=torch.float64)\n",
      "1260 tensor(1.9789, dtype=torch.float64) tensor(0.0627, dtype=torch.float64)\n",
      "1270 tensor(1.7908, dtype=torch.float64) tensor(0.0643, dtype=torch.float64)\n",
      "1280 tensor(1.6206, dtype=torch.float64) tensor(0.0660, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1290 tensor(1.4669, dtype=torch.float64) tensor(0.0677, dtype=torch.float64)\n",
      "1300 tensor(1.3280, dtype=torch.float64) tensor(0.0696, dtype=torch.float64)\n",
      "1310 tensor(1.2030, dtype=torch.float64) tensor(0.0718, dtype=torch.float64)\n",
      "1320 tensor(1.0922, dtype=torch.float64) tensor(0.0751, dtype=torch.float64)\n",
      "1330 tensor(1.1604, dtype=torch.float64) tensor(0.0728, dtype=torch.float64)\n",
      "1340 tensor(1.0687, dtype=torch.float64) tensor(0.0785, dtype=torch.float64)\n",
      "1350 tensor(1.0803, dtype=torch.float64) tensor(0.0795, dtype=torch.float64)\n",
      "1360 tensor(1.5849, dtype=torch.float64) tensor(0.0664, dtype=torch.float64)\n",
      "1370 tensor(1.4346, dtype=torch.float64) tensor(0.0681, dtype=torch.float64)\n",
      "1380 tensor(1.2989, dtype=torch.float64) tensor(0.0701, dtype=torch.float64)\n",
      "1390 tensor(1.1769, dtype=torch.float64) tensor(0.0724, dtype=torch.float64)\n",
      "1400 tensor(1.0714, dtype=torch.float64) tensor(0.0764, dtype=torch.float64)\n",
      "1410 tensor(2.3652, dtype=torch.float64) tensor(0.0672, dtype=torch.float64)\n",
      "1420 tensor(2.1400, dtype=torch.float64) tensor(0.0688, dtype=torch.float64)\n",
      "1430 tensor(1.9364, dtype=torch.float64) tensor(0.0704, dtype=torch.float64)\n",
      "1440 tensor(1.7523, dtype=torch.float64) tensor(0.0720, dtype=torch.float64)\n",
      "1450 tensor(1.5858, dtype=torch.float64) tensor(0.0736, dtype=torch.float64)\n",
      "1460 tensor(1.4354, dtype=torch.float64) tensor(0.0754, dtype=torch.float64)\n",
      "1470 tensor(1.2996, dtype=torch.float64) tensor(0.0773, dtype=torch.float64)\n",
      "1480 tensor(1.1773, dtype=torch.float64) tensor(0.0795, dtype=torch.float64)\n",
      "1490 tensor(1.0701, dtype=torch.float64) tensor(0.0831, dtype=torch.float64)\n",
      "1500 tensor(16.5698, dtype=torch.float64) tensor(0.1687, dtype=torch.float64)\n",
      "1510 tensor(14.9895, dtype=torch.float64) tensor(0.1632, dtype=torch.float64)\n",
      "1520 tensor(13.5599, dtype=torch.float64) tensor(0.1579, dtype=torch.float64)\n",
      "1530 tensor(12.2667, dtype=torch.float64) tensor(0.1528, dtype=torch.float64)\n",
      "1540 tensor(11.0969, dtype=torch.float64) tensor(0.1480, dtype=torch.float64)\n",
      "1550 tensor(10.0386, dtype=torch.float64) tensor(0.1434, dtype=torch.float64)\n",
      "1560 tensor(9.0813, dtype=torch.float64) tensor(0.1390, dtype=torch.float64)\n",
      "1570 tensor(8.2153, dtype=torch.float64) tensor(0.1348, dtype=torch.float64)\n",
      "1580 tensor(7.4320, dtype=torch.float64) tensor(0.1307, dtype=torch.float64)\n",
      "1590 tensor(6.7233, dtype=torch.float64) tensor(0.1268, dtype=torch.float64)\n",
      "1600 tensor(6.0823, dtype=torch.float64) tensor(0.1231, dtype=torch.float64)\n",
      "1610 tensor(5.5024, dtype=torch.float64) tensor(0.1195, dtype=torch.float64)\n",
      "1620 tensor(4.9779, dtype=torch.float64) tensor(0.1161, dtype=torch.float64)\n",
      "1630 tensor(4.5033, dtype=torch.float64) tensor(0.1128, dtype=torch.float64)\n",
      "1640 tensor(4.0741, dtype=torch.float64) tensor(0.1096, dtype=torch.float64)\n",
      "1650 tensor(3.6858, dtype=torch.float64) tensor(0.1064, dtype=torch.float64)\n",
      "1660 tensor(3.3346, dtype=torch.float64) tensor(0.1034, dtype=torch.float64)\n",
      "1670 tensor(3.0169, dtype=torch.float64) tensor(0.1005, dtype=torch.float64)\n",
      "1680 tensor(2.7295, dtype=torch.float64) tensor(0.0976, dtype=torch.float64)\n",
      "1690 tensor(2.4695, dtype=torch.float64) tensor(0.0948, dtype=torch.float64)\n",
      "1700 tensor(2.2344, dtype=torch.float64) tensor(0.0921, dtype=torch.float64)\n",
      "1710 tensor(2.0218, dtype=torch.float64) tensor(0.0893, dtype=torch.float64)\n",
      "1720 tensor(1.8295, dtype=torch.float64) tensor(0.0866, dtype=torch.float64)\n",
      "1730 tensor(1.6556, dtype=torch.float64) tensor(0.0838, dtype=torch.float64)\n",
      "1740 tensor(1.4984, dtype=torch.float64) tensor(0.0808, dtype=torch.float64)\n",
      "1750 tensor(1.3564, dtype=torch.float64) tensor(0.0777, dtype=torch.float64)\n",
      "1760 tensor(1.2295, dtype=torch.float64) tensor(0.0806, dtype=torch.float64)\n",
      "1770 tensor(1.1147, dtype=torch.float64) tensor(0.0852, dtype=torch.float64)\n",
      "1780 tensor(2.1287, dtype=torch.float64) tensor(0.0739, dtype=torch.float64)\n",
      "1790 tensor(1.9262, dtype=torch.float64) tensor(0.0755, dtype=torch.float64)\n",
      "1800 tensor(1.7430, dtype=torch.float64) tensor(0.0771, dtype=torch.float64)\n",
      "1810 tensor(1.5774, dtype=torch.float64) tensor(0.0788, dtype=torch.float64)\n",
      "1820 tensor(1.4278, dtype=torch.float64) tensor(0.0805, dtype=torch.float64)\n",
      "1830 tensor(1.2928, dtype=torch.float64) tensor(0.0824, dtype=torch.float64)\n",
      "1840 tensor(1.1712, dtype=torch.float64) tensor(0.0847, dtype=torch.float64)\n",
      "1850 tensor(1.0653, dtype=torch.float64) tensor(0.0884, dtype=torch.float64)\n",
      "1860 tensor(1.0508, dtype=torch.float64) tensor(0.0935, dtype=torch.float64)\n",
      "1870 tensor(1.3302, dtype=torch.float64) tensor(0.0840, dtype=torch.float64)\n",
      "1880 tensor(1.2048, dtype=torch.float64) tensor(0.0861, dtype=torch.float64)\n",
      "1890 tensor(1.0928, dtype=torch.float64) tensor(0.0889, dtype=torch.float64)\n",
      "1900 tensor(1.0678, dtype=torch.float64) tensor(0.0900, dtype=torch.float64)\n",
      "1910 tensor(2.2094, dtype=torch.float64) tensor(0.0755, dtype=torch.float64)\n",
      "1920 tensor(1.9991, dtype=torch.float64) tensor(0.0771, dtype=torch.float64)\n",
      "1930 tensor(1.8090, dtype=torch.float64) tensor(0.0787, dtype=torch.float64)\n",
      "1940 tensor(1.6371, dtype=torch.float64) tensor(0.0803, dtype=torch.float64)\n",
      "1950 tensor(1.4817, dtype=torch.float64) tensor(0.0820, dtype=torch.float64)\n",
      "1960 tensor(1.3413, dtype=torch.float64) tensor(0.0838, dtype=torch.float64)\n",
      "1970 tensor(1.2147, dtype=torch.float64) tensor(0.0859, dtype=torch.float64)\n",
      "1980 tensor(1.1015, dtype=torch.float64) tensor(0.0886, dtype=torch.float64)\n",
      "1990 tensor(1.0507, dtype=torch.float64) tensor(0.0935, dtype=torch.float64)\n",
      "2000 tensor(1.4499, dtype=torch.float64) tensor(0.0824, dtype=torch.float64)\n",
      "2010 tensor(1.3126, dtype=torch.float64) tensor(0.0843, dtype=torch.float64)\n",
      "2020 tensor(1.1890, dtype=torch.float64) tensor(0.0864, dtype=torch.float64)\n",
      "2030 tensor(1.0790, dtype=torch.float64) tensor(0.0894, dtype=torch.float64)\n",
      "2040 tensor(2.0611, dtype=torch.float64) tensor(0.0974, dtype=torch.float64)\n",
      "2050 tensor(1.8650, dtype=torch.float64) tensor(0.0947, dtype=torch.float64)\n",
      "2060 tensor(1.6877, dtype=torch.float64) tensor(0.0919, dtype=torch.float64)\n",
      "2070 tensor(1.5274, dtype=torch.float64) tensor(0.0891, dtype=torch.float64)\n",
      "2080 tensor(1.3826, dtype=torch.float64) tensor(0.0860, dtype=torch.float64)\n",
      "2090 tensor(1.2530, dtype=torch.float64) tensor(0.0869, dtype=torch.float64)\n",
      "2100 tensor(1.1354, dtype=torch.float64) tensor(0.0910, dtype=torch.float64)\n",
      "2110 tensor(2.1362, dtype=torch.float64) tensor(0.0812, dtype=torch.float64)\n",
      "2120 tensor(1.9329, dtype=torch.float64) tensor(0.0827, dtype=torch.float64)\n",
      "2130 tensor(1.7491, dtype=torch.float64) tensor(0.0843, dtype=torch.float64)\n",
      "2140 tensor(1.5830, dtype=torch.float64) tensor(0.0860, dtype=torch.float64)\n",
      "2150 tensor(1.4328, dtype=torch.float64) tensor(0.0877, dtype=torch.float64)\n",
      "2160 tensor(1.2972, dtype=torch.float64) tensor(0.0896, dtype=torch.float64)\n",
      "2170 tensor(1.1750, dtype=torch.float64) tensor(0.0918, dtype=torch.float64)\n",
      "2180 tensor(1.0671, dtype=torch.float64) tensor(0.0950, dtype=torch.float64)\n",
      "2190 tensor(3.9046, dtype=torch.float64) tensor(0.0711, dtype=torch.float64)\n",
      "2200 tensor(3.5325, dtype=torch.float64) tensor(0.0729, dtype=torch.float64)\n",
      "2210 tensor(3.1959, dtype=torch.float64) tensor(0.0746, dtype=torch.float64)\n",
      "2220 tensor(2.8914, dtype=torch.float64) tensor(0.0763, dtype=torch.float64)\n",
      "2230 tensor(2.6160, dtype=torch.float64) tensor(0.0779, dtype=torch.float64)\n",
      "2240 tensor(2.3669, dtype=torch.float64) tensor(0.0795, dtype=torch.float64)\n",
      "2250 tensor(2.1416, dtype=torch.float64) tensor(0.0811, dtype=torch.float64)\n",
      "2260 tensor(1.9378, dtype=torch.float64) tensor(0.0827, dtype=torch.float64)\n",
      "2270 tensor(1.7535, dtype=torch.float64) tensor(0.0843, dtype=torch.float64)\n",
      "2280 tensor(1.5869, dtype=torch.float64) tensor(0.0859, dtype=torch.float64)\n",
      "2290 tensor(1.4363, dtype=torch.float64) tensor(0.0877, dtype=torch.float64)\n",
      "2300 tensor(1.3004, dtype=torch.float64) tensor(0.0895, dtype=torch.float64)\n",
      "2310 tensor(1.1779, dtype=torch.float64) tensor(0.0917, dtype=torch.float64)\n",
      "2320 tensor(1.0696, dtype=torch.float64) tensor(0.0949, dtype=torch.float64)\n",
      "2330 tensor(1.0462, dtype=torch.float64) tensor(0.0969, dtype=torch.float64)\n",
      "2340 tensor(1.0745, dtype=torch.float64) tensor(0.0954, dtype=torch.float64)\n",
      "2350 tensor(1.0542, dtype=torch.float64) tensor(0.0976, dtype=torch.float64)\n",
      "2360 tensor(2.4539, dtype=torch.float64) tensor(0.1020, dtype=torch.float64)\n",
      "2370 tensor(2.2202, dtype=torch.float64) tensor(0.0993, dtype=torch.float64)\n",
      "2380 tensor(2.0089, dtype=torch.float64) tensor(0.0965, dtype=torch.float64)\n",
      "2390 tensor(1.8178, dtype=torch.float64) tensor(0.0938, dtype=torch.float64)\n",
      "2400 tensor(1.6450, dtype=torch.float64) tensor(0.0910, dtype=torch.float64)\n",
      "2410 tensor(1.4889, dtype=torch.float64) tensor(0.0881, dtype=torch.float64)\n",
      "2420 tensor(1.3477, dtype=torch.float64) tensor(0.0850, dtype=torch.float64)\n",
      "2430 tensor(1.2215, dtype=torch.float64) tensor(0.0878, dtype=torch.float64)\n",
      "2440 tensor(1.1074, dtype=torch.float64) tensor(0.0923, dtype=torch.float64)\n",
      "2450 tensor(1.0645, dtype=torch.float64) tensor(0.0955, dtype=torch.float64)\n",
      "2460 tensor(1.0397, dtype=torch.float64) tensor(0.1004, dtype=torch.float64)\n",
      "2470 tensor(1.4759, dtype=torch.float64) tensor(0.0963, dtype=torch.float64)\n",
      "2480 tensor(1.3360, dtype=torch.float64) tensor(0.0981, dtype=torch.float64)\n",
      "2490 tensor(1.2098, dtype=torch.float64) tensor(0.1001, dtype=torch.float64)\n",
      "2500 tensor(1.0967, dtype=torch.float64) tensor(0.1026, dtype=torch.float64)\n",
      "2510 tensor(1.0873, dtype=torch.float64) tensor(0.1029, dtype=torch.float64)\n",
      "2520 tensor(2.0582, dtype=torch.float64) tensor(0.0910, dtype=torch.float64)\n",
      "2530 tensor(1.8624, dtype=torch.float64) tensor(0.0925, dtype=torch.float64)\n",
      "2540 tensor(1.6853, dtype=torch.float64) tensor(0.0941, dtype=torch.float64)\n",
      "2550 tensor(1.5252, dtype=torch.float64) tensor(0.0958, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560 tensor(1.3806, dtype=torch.float64) tensor(0.0975, dtype=torch.float64)\n",
      "2570 tensor(1.2500, dtype=torch.float64) tensor(0.0994, dtype=torch.float64)\n",
      "2580 tensor(1.1325, dtype=torch.float64) tensor(0.1017, dtype=torch.float64)\n",
      "2590 tensor(1.0309, dtype=torch.float64) tensor(0.1055, dtype=torch.float64)\n",
      "2600 tensor(1.0615, dtype=torch.float64) tensor(0.1098, dtype=torch.float64)\n",
      "2610 tensor(1.4963, dtype=torch.float64) tensor(0.0961, dtype=torch.float64)\n",
      "2620 tensor(1.3545, dtype=torch.float64) tensor(0.0978, dtype=torch.float64)\n",
      "2630 tensor(1.2265, dtype=torch.float64) tensor(0.0998, dtype=torch.float64)\n",
      "2640 tensor(1.1115, dtype=torch.float64) tensor(0.1022, dtype=torch.float64)\n",
      "2650 tensor(1.0732, dtype=torch.float64) tensor(0.1102, dtype=torch.float64)\n",
      "2660 tensor(1.0247, dtype=torch.float64) tensor(0.1066, dtype=torch.float64)\n",
      "2670 tensor(18.4143, dtype=torch.float64) tensor(0.1159, dtype=torch.float64)\n",
      "2680 tensor(16.6580, dtype=torch.float64) tensor(0.1125, dtype=torch.float64)\n",
      "2690 tensor(15.0693, dtype=torch.float64) tensor(0.1093, dtype=torch.float64)\n",
      "2700 tensor(13.6321, dtype=torch.float64) tensor(0.1062, dtype=torch.float64)\n",
      "2710 tensor(12.3320, dtype=torch.float64) tensor(0.1033, dtype=torch.float64)\n",
      "2720 tensor(11.1559, dtype=torch.float64) tensor(0.1005, dtype=torch.float64)\n",
      "2730 tensor(10.0920, dtype=torch.float64) tensor(0.0978, dtype=torch.float64)\n",
      "2740 tensor(9.1296, dtype=torch.float64) tensor(0.0953, dtype=torch.float64)\n",
      "2750 tensor(8.2590, dtype=torch.float64) tensor(0.0929, dtype=torch.float64)\n",
      "2760 tensor(7.4715, dtype=torch.float64) tensor(0.0905, dtype=torch.float64)\n",
      "2770 tensor(6.7591, dtype=torch.float64) tensor(0.0883, dtype=torch.float64)\n",
      "2780 tensor(6.1146, dtype=torch.float64) tensor(0.0861, dtype=torch.float64)\n",
      "2790 tensor(5.5316, dtype=torch.float64) tensor(0.0840, dtype=torch.float64)\n",
      "2800 tensor(5.0043, dtype=torch.float64) tensor(0.0831, dtype=torch.float64)\n",
      "2810 tensor(4.5272, dtype=torch.float64) tensor(0.0850, dtype=torch.float64)\n",
      "2820 tensor(4.0957, dtype=torch.float64) tensor(0.0869, dtype=torch.float64)\n",
      "2830 tensor(3.7053, dtype=torch.float64) tensor(0.0886, dtype=torch.float64)\n",
      "2840 tensor(3.3522, dtype=torch.float64) tensor(0.0904, dtype=torch.float64)\n",
      "2850 tensor(3.0328, dtype=torch.float64) tensor(0.0921, dtype=torch.float64)\n",
      "2860 tensor(2.7439, dtype=torch.float64) tensor(0.0937, dtype=torch.float64)\n",
      "2870 tensor(2.4825, dtype=torch.float64) tensor(0.0953, dtype=torch.float64)\n",
      "2880 tensor(2.2462, dtype=torch.float64) tensor(0.0969, dtype=torch.float64)\n",
      "2890 tensor(2.0324, dtype=torch.float64) tensor(0.0985, dtype=torch.float64)\n",
      "2900 tensor(1.8390, dtype=torch.float64) tensor(0.1000, dtype=torch.float64)\n",
      "2910 tensor(1.6642, dtype=torch.float64) tensor(0.1016, dtype=torch.float64)\n",
      "2920 tensor(1.5061, dtype=torch.float64) tensor(0.1033, dtype=torch.float64)\n",
      "2930 tensor(1.3632, dtype=torch.float64) tensor(0.1050, dtype=torch.float64)\n",
      "2940 tensor(1.2343, dtype=torch.float64) tensor(0.1069, dtype=torch.float64)\n",
      "2950 tensor(1.1184, dtype=torch.float64) tensor(0.1091, dtype=torch.float64)\n",
      "2960 tensor(1.0187, dtype=torch.float64) tensor(0.1132, dtype=torch.float64)\n",
      "2970 tensor(1.0247, dtype=torch.float64) tensor(0.1126, dtype=torch.float64)\n",
      "2980 tensor(1.9032, dtype=torch.float64) tensor(0.0995, dtype=torch.float64)\n",
      "2990 tensor(1.7222, dtype=torch.float64) tensor(0.1011, dtype=torch.float64)\n",
      "3000 tensor(1.5585, dtype=torch.float64) tensor(0.1027, dtype=torch.float64)\n",
      "3010 tensor(1.4106, dtype=torch.float64) tensor(0.1044, dtype=torch.float64)\n",
      "3020 tensor(1.2771, dtype=torch.float64) tensor(0.1062, dtype=torch.float64)\n",
      "3030 tensor(1.1567, dtype=torch.float64) tensor(0.1083, dtype=torch.float64)\n",
      "3040 tensor(1.0497, dtype=torch.float64) tensor(0.1112, dtype=torch.float64)\n",
      "3050 tensor(1.0147, dtype=torch.float64) tensor(0.1140, dtype=torch.float64)\n",
      "3060 tensor(11.2558, dtype=torch.float64) tensor(0.1085, dtype=torch.float64)\n",
      "3070 tensor(10.1824, dtype=torch.float64) tensor(0.1059, dtype=torch.float64)\n",
      "3080 tensor(9.2114, dtype=torch.float64) tensor(0.1033, dtype=torch.float64)\n",
      "3090 tensor(8.3330, dtype=torch.float64) tensor(0.1008, dtype=torch.float64)\n",
      "3100 tensor(7.5384, dtype=torch.float64) tensor(0.0985, dtype=torch.float64)\n",
      "3110 tensor(6.8196, dtype=torch.float64) tensor(0.0962, dtype=torch.float64)\n",
      "3120 tensor(6.1693, dtype=torch.float64) tensor(0.0941, dtype=torch.float64)\n",
      "3130 tensor(5.5811, dtype=torch.float64) tensor(0.0920, dtype=torch.float64)\n",
      "3140 tensor(5.0491, dtype=torch.float64) tensor(0.0903, dtype=torch.float64)\n",
      "3150 tensor(4.5677, dtype=torch.float64) tensor(0.0922, dtype=torch.float64)\n",
      "3160 tensor(4.1323, dtype=torch.float64) tensor(0.0941, dtype=torch.float64)\n",
      "3170 tensor(3.7385, dtype=torch.float64) tensor(0.0959, dtype=torch.float64)\n",
      "3180 tensor(3.3822, dtype=torch.float64) tensor(0.0976, dtype=torch.float64)\n",
      "3190 tensor(3.0599, dtype=torch.float64) tensor(0.0993, dtype=torch.float64)\n",
      "3200 tensor(2.7684, dtype=torch.float64) tensor(0.1009, dtype=torch.float64)\n",
      "3210 tensor(2.5047, dtype=torch.float64) tensor(0.1025, dtype=torch.float64)\n",
      "3220 tensor(2.2662, dtype=torch.float64) tensor(0.1041, dtype=torch.float64)\n",
      "3230 tensor(2.0505, dtype=torch.float64) tensor(0.1057, dtype=torch.float64)\n",
      "3240 tensor(1.8554, dtype=torch.float64) tensor(0.1072, dtype=torch.float64)\n",
      "3250 tensor(1.6789, dtype=torch.float64) tensor(0.1088, dtype=torch.float64)\n",
      "3260 tensor(1.5194, dtype=torch.float64) tensor(0.1104, dtype=torch.float64)\n",
      "3270 tensor(1.3753, dtype=torch.float64) tensor(0.1121, dtype=torch.float64)\n",
      "3280 tensor(1.2451, dtype=torch.float64) tensor(0.1139, dtype=torch.float64)\n",
      "3290 tensor(1.1279, dtype=torch.float64) tensor(0.1161, dtype=torch.float64)\n",
      "3300 tensor(1.0245, dtype=torch.float64) tensor(0.1194, dtype=torch.float64)\n",
      "3310 tensor(1.1694, dtype=torch.float64) tensor(0.1153, dtype=torch.float64)\n",
      "3320 tensor(1.0604, dtype=torch.float64) tensor(0.1179, dtype=torch.float64)\n",
      "3330 tensor(8.8530, dtype=torch.float64) tensor(0.1023, dtype=torch.float64)\n",
      "3340 tensor(8.0088, dtype=torch.float64) tensor(0.0999, dtype=torch.float64)\n",
      "3350 tensor(7.2451, dtype=torch.float64) tensor(0.0976, dtype=torch.float64)\n",
      "3360 tensor(6.5543, dtype=torch.float64) tensor(0.0954, dtype=torch.float64)\n",
      "3370 tensor(5.9293, dtype=torch.float64) tensor(0.0932, dtype=torch.float64)\n",
      "3380 tensor(5.3640, dtype=torch.float64) tensor(0.0912, dtype=torch.float64)\n",
      "3390 tensor(4.8527, dtype=torch.float64) tensor(0.0911, dtype=torch.float64)\n",
      "3400 tensor(4.3901, dtype=torch.float64) tensor(0.0930, dtype=torch.float64)\n",
      "3410 tensor(3.9716, dtype=torch.float64) tensor(0.0948, dtype=torch.float64)\n",
      "3420 tensor(3.5931, dtype=torch.float64) tensor(0.0966, dtype=torch.float64)\n",
      "3430 tensor(3.2507, dtype=torch.float64) tensor(0.0983, dtype=torch.float64)\n",
      "3440 tensor(2.9410, dtype=torch.float64) tensor(0.0999, dtype=torch.float64)\n",
      "3450 tensor(2.6608, dtype=torch.float64) tensor(0.1016, dtype=torch.float64)\n",
      "3460 tensor(2.4074, dtype=torch.float64) tensor(0.1032, dtype=torch.float64)\n",
      "3470 tensor(2.1782, dtype=torch.float64) tensor(0.1047, dtype=torch.float64)\n",
      "3480 tensor(1.9709, dtype=torch.float64) tensor(0.1063, dtype=torch.float64)\n",
      "3490 tensor(1.7834, dtype=torch.float64) tensor(0.1079, dtype=torch.float64)\n",
      "3500 tensor(1.6139, dtype=torch.float64) tensor(0.1094, dtype=torch.float64)\n",
      "3510 tensor(1.4606, dtype=torch.float64) tensor(0.1111, dtype=torch.float64)\n",
      "3520 tensor(1.3221, dtype=torch.float64) tensor(0.1128, dtype=torch.float64)\n",
      "3530 tensor(1.1972, dtype=torch.float64) tensor(0.1148, dtype=torch.float64)\n",
      "3540 tensor(1.0851, dtype=torch.float64) tensor(0.1172, dtype=torch.float64)\n",
      "3550 tensor(1.0266, dtype=torch.float64) tensor(0.1193, dtype=torch.float64)\n",
      "3560 tensor(1.7577, dtype=torch.float64) tensor(0.1081, dtype=torch.float64)\n",
      "3570 tensor(1.5906, dtype=torch.float64) tensor(0.1097, dtype=torch.float64)\n",
      "3580 tensor(1.4396, dtype=torch.float64) tensor(0.1113, dtype=torch.float64)\n",
      "3590 tensor(1.3032, dtype=torch.float64) tensor(0.1131, dtype=torch.float64)\n",
      "3600 tensor(1.1801, dtype=torch.float64) tensor(0.1151, dtype=torch.float64)\n",
      "3610 tensor(1.0699, dtype=torch.float64) tensor(0.1176, dtype=torch.float64)\n",
      "3620 tensor(1.0103, dtype=torch.float64) tensor(0.1227, dtype=torch.float64)\n",
      "3630 tensor(1.3149, dtype=torch.float64) tensor(0.1129, dtype=torch.float64)\n",
      "3640 tensor(1.1907, dtype=torch.float64) tensor(0.1149, dtype=torch.float64)\n",
      "3650 tensor(1.0792, dtype=torch.float64) tensor(0.1173, dtype=torch.float64)\n",
      "3660 tensor(1.0492, dtype=torch.float64) tensor(0.1249, dtype=torch.float64)\n",
      "3670 tensor(1.0049, dtype=torch.float64) tensor(0.1218, dtype=torch.float64)\n",
      "3680 tensor(1.0577, dtype=torch.float64) tensor(0.1180, dtype=torch.float64)\n",
      "3690 tensor(1.1453, dtype=torch.float64) tensor(0.1274, dtype=torch.float64)\n",
      "3700 tensor(1.0393, dtype=torch.float64) tensor(0.1245, dtype=torch.float64)\n",
      "3710 tensor(1.2160, dtype=torch.float64) tensor(0.1144, dtype=torch.float64)\n",
      "3720 tensor(1.1019, dtype=torch.float64) tensor(0.1167, dtype=torch.float64)\n",
      "3730 tensor(1.0056, dtype=torch.float64) tensor(0.1211, dtype=torch.float64)\n",
      "3740 tensor(1.0049, dtype=torch.float64) tensor(0.1218, dtype=torch.float64)\n",
      "3750 tensor(1.0506, dtype=torch.float64) tensor(0.1182, dtype=torch.float64)\n",
      "3760 tensor(1.0115, dtype=torch.float64) tensor(0.1229, dtype=torch.float64)\n",
      "3770 tensor(1.0262, dtype=torch.float64) tensor(0.1193, dtype=torch.float64)\n",
      "3780 tensor(1.1539, dtype=torch.float64) tensor(0.1156, dtype=torch.float64)\n",
      "3790 tensor(1.0468, dtype=torch.float64) tensor(0.1184, dtype=torch.float64)\n",
      "3800 tensor(1.4387, dtype=torch.float64) tensor(0.1188, dtype=torch.float64)\n",
      "3810 tensor(1.3023, dtype=torch.float64) tensor(0.1205, dtype=torch.float64)\n",
      "3820 tensor(1.1793, dtype=torch.float64) tensor(0.1224, dtype=torch.float64)\n",
      "3830 tensor(1.0689, dtype=torch.float64) tensor(0.1249, dtype=torch.float64)\n",
      "3840 tensor(1.0259, dtype=torch.float64) tensor(0.1319, dtype=torch.float64)\n",
      "3850 tensor(1.2031, dtype=torch.float64) tensor(0.1238, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860 tensor(1.0904, dtype=torch.float64) tensor(0.1277, dtype=torch.float64)\n",
      "3870 tensor(0.9935, dtype=torch.float64) tensor(0.1347, dtype=torch.float64)\n",
      "3880 tensor(1.0220, dtype=torch.float64) tensor(0.1318, dtype=torch.float64)\n",
      "3890 tensor(0.9852, dtype=torch.float64) tensor(0.1366, dtype=torch.float64)\n",
      "3900 tensor(5.7698, dtype=torch.float64) tensor(0.1668, dtype=torch.float64)\n",
      "3910 tensor(5.2197, dtype=torch.float64) tensor(0.1634, dtype=torch.float64)\n",
      "3920 tensor(4.7221, dtype=torch.float64) tensor(0.1600, dtype=torch.float64)\n",
      "3930 tensor(4.2720, dtype=torch.float64) tensor(0.1568, dtype=torch.float64)\n",
      "3940 tensor(3.8648, dtype=torch.float64) tensor(0.1537, dtype=torch.float64)\n",
      "3950 tensor(3.4965, dtype=torch.float64) tensor(0.1506, dtype=torch.float64)\n",
      "3960 tensor(3.1633, dtype=torch.float64) tensor(0.1477, dtype=torch.float64)\n",
      "3970 tensor(2.8619, dtype=torch.float64) tensor(0.1449, dtype=torch.float64)\n",
      "3980 tensor(2.5893, dtype=torch.float64) tensor(0.1421, dtype=torch.float64)\n",
      "3990 tensor(2.3427, dtype=torch.float64) tensor(0.1393, dtype=torch.float64)\n",
      "4000 tensor(2.1196, dtype=torch.float64) tensor(0.1367, dtype=torch.float64)\n",
      "4010 tensor(1.9179, dtype=torch.float64) tensor(0.1340, dtype=torch.float64)\n",
      "4020 tensor(1.7354, dtype=torch.float64) tensor(0.1313, dtype=torch.float64)\n",
      "4030 tensor(1.5705, dtype=torch.float64) tensor(0.1286, dtype=torch.float64)\n",
      "4040 tensor(1.4214, dtype=torch.float64) tensor(0.1258, dtype=torch.float64)\n",
      "4050 tensor(1.2866, dtype=torch.float64) tensor(0.1228, dtype=torch.float64)\n",
      "4060 tensor(1.1664, dtype=torch.float64) tensor(0.1250, dtype=torch.float64)\n",
      "4070 tensor(1.0574, dtype=torch.float64) tensor(0.1293, dtype=torch.float64)\n",
      "4080 tensor(1.0107, dtype=torch.float64) tensor(0.1325, dtype=torch.float64)\n",
      "4090 tensor(0.9980, dtype=torch.float64) tensor(0.1335, dtype=torch.float64)\n",
      "4100 tensor(1.1785, dtype=torch.float64) tensor(0.1432, dtype=torch.float64)\n",
      "4110 tensor(1.0681, dtype=torch.float64) tensor(0.1408, dtype=torch.float64)\n",
      "4120 tensor(1.0664, dtype=torch.float64) tensor(0.1319, dtype=torch.float64)\n",
      "4130 tensor(0.9754, dtype=torch.float64) tensor(0.1441, dtype=torch.float64)\n",
      "4140 tensor(1.1170, dtype=torch.float64) tensor(0.1381, dtype=torch.float64)\n",
      "4150 tensor(1.0134, dtype=torch.float64) tensor(0.1409, dtype=torch.float64)\n",
      "4160 tensor(0.9754, dtype=torch.float64) tensor(0.1438, dtype=torch.float64)\n",
      "4170 tensor(2.1218, dtype=torch.float64) tensor(0.1347, dtype=torch.float64)\n",
      "4180 tensor(1.9199, dtype=torch.float64) tensor(0.1363, dtype=torch.float64)\n",
      "4190 tensor(1.7372, dtype=torch.float64) tensor(0.1378, dtype=torch.float64)\n",
      "4200 tensor(1.5721, dtype=torch.float64) tensor(0.1394, dtype=torch.float64)\n",
      "4210 tensor(1.4228, dtype=torch.float64) tensor(0.1410, dtype=torch.float64)\n",
      "4220 tensor(1.2878, dtype=torch.float64) tensor(0.1426, dtype=torch.float64)\n",
      "4230 tensor(1.1661, dtype=torch.float64) tensor(0.1445, dtype=torch.float64)\n",
      "4240 tensor(1.0566, dtype=torch.float64) tensor(0.1468, dtype=torch.float64)\n",
      "4250 tensor(0.9659, dtype=torch.float64) tensor(0.1513, dtype=torch.float64)\n",
      "4260 tensor(3.2020, dtype=torch.float64) tensor(0.1721, dtype=torch.float64)\n",
      "4270 tensor(2.8969, dtype=torch.float64) tensor(0.1692, dtype=torch.float64)\n",
      "4280 tensor(2.6209, dtype=torch.float64) tensor(0.1664, dtype=torch.float64)\n",
      "4290 tensor(2.3713, dtype=torch.float64) tensor(0.1637, dtype=torch.float64)\n",
      "4300 tensor(2.1455, dtype=torch.float64) tensor(0.1611, dtype=torch.float64)\n",
      "4310 tensor(1.9413, dtype=torch.float64) tensor(0.1584, dtype=torch.float64)\n",
      "4320 tensor(1.7565, dtype=torch.float64) tensor(0.1558, dtype=torch.float64)\n",
      "4330 tensor(1.5895, dtype=torch.float64) tensor(0.1531, dtype=torch.float64)\n",
      "4340 tensor(1.4385, dtype=torch.float64) tensor(0.1504, dtype=torch.float64)\n",
      "4350 tensor(1.3021, dtype=torch.float64) tensor(0.1476, dtype=torch.float64)\n",
      "4360 tensor(1.1792, dtype=torch.float64) tensor(0.1462, dtype=torch.float64)\n",
      "4370 tensor(1.0691, dtype=torch.float64) tensor(0.1499, dtype=torch.float64)\n",
      "4380 tensor(0.9721, dtype=torch.float64) tensor(0.1559, dtype=torch.float64)\n",
      "4390 tensor(0.9746, dtype=torch.float64) tensor(0.1554, dtype=torch.float64)\n",
      "4400 tensor(0.9586, dtype=torch.float64) tensor(0.1599, dtype=torch.float64)\n",
      "4410 tensor(0.9583, dtype=torch.float64) tensor(0.1585, dtype=torch.float64)\n",
      "4420 tensor(1.0309, dtype=torch.float64) tensor(0.1515, dtype=torch.float64)\n",
      "4430 tensor(1.0312, dtype=torch.float64) tensor(0.1536, dtype=torch.float64)\n",
      "4440 tensor(0.9712, dtype=torch.float64) tensor(0.1573, dtype=torch.float64)\n",
      "4450 tensor(0.9573, dtype=torch.float64) tensor(0.1596, dtype=torch.float64)\n",
      "4460 tensor(1.0417, dtype=torch.float64) tensor(0.1546, dtype=torch.float64)\n",
      "4470 tensor(0.9589, dtype=torch.float64) tensor(0.1599, dtype=torch.float64)\n",
      "4480 tensor(0.9940, dtype=torch.float64) tensor(0.1561, dtype=torch.float64)\n",
      "4490 tensor(2.1289, dtype=torch.float64) tensor(0.1605, dtype=torch.float64)\n",
      "4500 tensor(1.9262, dtype=torch.float64) tensor(0.1579, dtype=torch.float64)\n",
      "4510 tensor(1.7430, dtype=torch.float64) tensor(0.1552, dtype=torch.float64)\n",
      "4520 tensor(1.5773, dtype=torch.float64) tensor(0.1526, dtype=torch.float64)\n",
      "4530 tensor(1.4274, dtype=torch.float64) tensor(0.1498, dtype=torch.float64)\n",
      "4540 tensor(1.2920, dtype=torch.float64) tensor(0.1470, dtype=torch.float64)\n",
      "4550 tensor(1.1706, dtype=torch.float64) tensor(0.1464, dtype=torch.float64)\n",
      "4560 tensor(1.0609, dtype=torch.float64) tensor(0.1502, dtype=torch.float64)\n",
      "4570 tensor(0.9657, dtype=torch.float64) tensor(0.1567, dtype=torch.float64)\n",
      "4580 tensor(0.9667, dtype=torch.float64) tensor(0.1577, dtype=torch.float64)\n",
      "4590 tensor(1.0062, dtype=torch.float64) tensor(0.1627, dtype=torch.float64)\n",
      "4600 tensor(1.0623, dtype=torch.float64) tensor(0.1501, dtype=torch.float64)\n",
      "4610 tensor(0.9664, dtype=torch.float64) tensor(0.1564, dtype=torch.float64)\n",
      "4620 tensor(1.0617, dtype=torch.float64) tensor(0.1527, dtype=torch.float64)\n",
      "4630 tensor(0.9662, dtype=torch.float64) tensor(0.1564, dtype=torch.float64)\n",
      "4640 tensor(0.9601, dtype=torch.float64) tensor(0.1600, dtype=torch.float64)\n",
      "4650 tensor(0.9630, dtype=torch.float64) tensor(0.1603, dtype=torch.float64)\n",
      "4660 tensor(0.9926, dtype=torch.float64) tensor(0.1561, dtype=torch.float64)\n",
      "4670 tensor(1.6794, dtype=torch.float64) tensor(0.1545, dtype=torch.float64)\n",
      "4680 tensor(1.5198, dtype=torch.float64) tensor(0.1519, dtype=torch.float64)\n",
      "4690 tensor(1.3755, dtype=torch.float64) tensor(0.1491, dtype=torch.float64)\n",
      "4700 tensor(1.2451, dtype=torch.float64) tensor(0.1461, dtype=torch.float64)\n",
      "4710 tensor(1.1286, dtype=torch.float64) tensor(0.1477, dtype=torch.float64)\n",
      "4720 tensor(1.0232, dtype=torch.float64) tensor(0.1520, dtype=torch.float64)\n",
      "4730 tensor(0.9612, dtype=torch.float64) tensor(0.1579, dtype=torch.float64)\n",
      "4740 tensor(1.0996, dtype=torch.float64) tensor(0.1650, dtype=torch.float64)\n",
      "4750 tensor(0.9975, dtype=torch.float64) tensor(0.1622, dtype=torch.float64)\n",
      "4760 tensor(1.0356, dtype=torch.float64) tensor(0.1547, dtype=torch.float64)\n",
      "4770 tensor(3.6773, dtype=torch.float64) tensor(0.1759, dtype=torch.float64)\n",
      "4780 tensor(3.3269, dtype=torch.float64) tensor(0.1729, dtype=torch.float64)\n",
      "4790 tensor(3.0098, dtype=torch.float64) tensor(0.1701, dtype=torch.float64)\n",
      "4800 tensor(2.7231, dtype=torch.float64) tensor(0.1673, dtype=torch.float64)\n",
      "4810 tensor(2.4637, dtype=torch.float64) tensor(0.1645, dtype=torch.float64)\n",
      "4820 tensor(2.2291, dtype=torch.float64) tensor(0.1619, dtype=torch.float64)\n",
      "4830 tensor(2.0169, dtype=torch.float64) tensor(0.1592, dtype=torch.float64)\n",
      "4840 tensor(1.8249, dtype=torch.float64) tensor(0.1566, dtype=torch.float64)\n",
      "4850 tensor(1.6514, dtype=torch.float64) tensor(0.1539, dtype=torch.float64)\n",
      "4860 tensor(1.4944, dtype=torch.float64) tensor(0.1512, dtype=torch.float64)\n",
      "4870 tensor(1.3526, dtype=torch.float64) tensor(0.1484, dtype=torch.float64)\n",
      "4880 tensor(1.2244, dtype=torch.float64) tensor(0.1454, dtype=torch.float64)\n",
      "4890 tensor(1.1100, dtype=torch.float64) tensor(0.1483, dtype=torch.float64)\n",
      "4900 tensor(1.0067, dtype=torch.float64) tensor(0.1529, dtype=torch.float64)\n",
      "4910 tensor(1.0394, dtype=torch.float64) tensor(0.1528, dtype=torch.float64)\n",
      "4920 tensor(0.9601, dtype=torch.float64) tensor(0.1605, dtype=torch.float64)\n",
      "4930 tensor(0.9595, dtype=torch.float64) tensor(0.1581, dtype=torch.float64)\n",
      "4940 tensor(1.9514, dtype=torch.float64) tensor(0.1435, dtype=torch.float64)\n",
      "4950 tensor(1.7658, dtype=torch.float64) tensor(0.1450, dtype=torch.float64)\n",
      "4960 tensor(1.5978, dtype=torch.float64) tensor(0.1466, dtype=torch.float64)\n",
      "4970 tensor(1.4460, dtype=torch.float64) tensor(0.1481, dtype=torch.float64)\n",
      "4980 tensor(1.3089, dtype=torch.float64) tensor(0.1498, dtype=torch.float64)\n",
      "4990 tensor(1.1850, dtype=torch.float64) tensor(0.1516, dtype=torch.float64)\n",
      "5000 tensor(1.0735, dtype=torch.float64) tensor(0.1537, dtype=torch.float64)\n",
      "5010 tensor(0.9751, dtype=torch.float64) tensor(0.1569, dtype=torch.float64)\n",
      "5020 tensor(1.0020, dtype=torch.float64) tensor(0.1557, dtype=torch.float64)\n",
      "5030 tensor(2.9309, dtype=torch.float64) tensor(0.1696, dtype=torch.float64)\n",
      "5040 tensor(2.6516, dtype=torch.float64) tensor(0.1668, dtype=torch.float64)\n",
      "5050 tensor(2.3991, dtype=torch.float64) tensor(0.1641, dtype=torch.float64)\n",
      "5060 tensor(2.1706, dtype=torch.float64) tensor(0.1614, dtype=torch.float64)\n",
      "5070 tensor(1.9640, dtype=torch.float64) tensor(0.1588, dtype=torch.float64)\n",
      "5080 tensor(1.7771, dtype=torch.float64) tensor(0.1561, dtype=torch.float64)\n",
      "5090 tensor(1.6081, dtype=torch.float64) tensor(0.1535, dtype=torch.float64)\n",
      "5100 tensor(1.4553, dtype=torch.float64) tensor(0.1508, dtype=torch.float64)\n",
      "5110 tensor(1.3172, dtype=torch.float64) tensor(0.1479, dtype=torch.float64)\n",
      "5120 tensor(1.1927, dtype=torch.float64) tensor(0.1458, dtype=torch.float64)\n",
      "5130 tensor(1.0814, dtype=torch.float64) tensor(0.1494, dtype=torch.float64)\n",
      "5140 tensor(0.9821, dtype=torch.float64) tensor(0.1548, dtype=torch.float64)\n",
      "5150 tensor(1.1274, dtype=torch.float64) tensor(0.1505, dtype=torch.float64)\n",
      "5160 tensor(1.0222, dtype=torch.float64) tensor(0.1531, dtype=torch.float64)\n",
      "5170 tensor(0.9653, dtype=torch.float64) tensor(0.1574, dtype=torch.float64)\n",
      "5180 tensor(1.0985, dtype=torch.float64) tensor(0.1605, dtype=torch.float64)\n",
      "5190 tensor(0.9962, dtype=torch.float64) tensor(0.1631, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 tensor(1.7280, dtype=torch.float64) tensor(0.1604, dtype=torch.float64)\n",
      "5210 tensor(1.5637, dtype=torch.float64) tensor(0.1619, dtype=torch.float64)\n",
      "5220 tensor(1.4151, dtype=torch.float64) tensor(0.1634, dtype=torch.float64)\n",
      "5230 tensor(1.2809, dtype=torch.float64) tensor(0.1651, dtype=torch.float64)\n",
      "5240 tensor(1.1597, dtype=torch.float64) tensor(0.1669, dtype=torch.float64)\n",
      "5250 tensor(1.0505, dtype=torch.float64) tensor(0.1690, dtype=torch.float64)\n",
      "5260 tensor(0.9544, dtype=torch.float64) tensor(0.1722, dtype=torch.float64)\n",
      "5270 tensor(1.2946, dtype=torch.float64) tensor(0.1649, dtype=torch.float64)\n",
      "5280 tensor(1.1720, dtype=torch.float64) tensor(0.1667, dtype=torch.float64)\n",
      "5290 tensor(1.0616, dtype=torch.float64) tensor(0.1687, dtype=torch.float64)\n",
      "5300 tensor(0.9637, dtype=torch.float64) tensor(0.1717, dtype=torch.float64)\n",
      "5310 tensor(0.9382, dtype=torch.float64) tensor(0.1738, dtype=torch.float64)\n",
      "5320 tensor(0.9424, dtype=torch.float64) tensor(0.1753, dtype=torch.float64)\n",
      "5330 tensor(8.8135, dtype=torch.float64) tensor(0.2230, dtype=torch.float64)\n",
      "5340 tensor(7.9730, dtype=torch.float64) tensor(0.2188, dtype=torch.float64)\n",
      "5350 tensor(7.2127, dtype=torch.float64) tensor(0.2149, dtype=torch.float64)\n",
      "5360 tensor(6.5250, dtype=torch.float64) tensor(0.2111, dtype=torch.float64)\n",
      "5370 tensor(5.9028, dtype=torch.float64) tensor(0.2074, dtype=torch.float64)\n",
      "5380 tensor(5.3400, dtype=torch.float64) tensor(0.2039, dtype=torch.float64)\n",
      "5390 tensor(4.8309, dtype=torch.float64) tensor(0.2006, dtype=torch.float64)\n",
      "5400 tensor(4.3704, dtype=torch.float64) tensor(0.1973, dtype=torch.float64)\n",
      "5410 tensor(3.9538, dtype=torch.float64) tensor(0.1942, dtype=torch.float64)\n",
      "5420 tensor(3.5769, dtype=torch.float64) tensor(0.1912, dtype=torch.float64)\n",
      "5430 tensor(3.2360, dtype=torch.float64) tensor(0.1883, dtype=torch.float64)\n",
      "5440 tensor(2.9277, dtype=torch.float64) tensor(0.1854, dtype=torch.float64)\n",
      "5450 tensor(2.6487, dtype=torch.float64) tensor(0.1827, dtype=torch.float64)\n",
      "5460 tensor(2.3964, dtype=torch.float64) tensor(0.1800, dtype=torch.float64)\n",
      "5470 tensor(2.1682, dtype=torch.float64) tensor(0.1773, dtype=torch.float64)\n",
      "5480 tensor(1.9618, dtype=torch.float64) tensor(0.1747, dtype=torch.float64)\n",
      "5490 tensor(1.7751, dtype=torch.float64) tensor(0.1721, dtype=torch.float64)\n",
      "5500 tensor(1.6063, dtype=torch.float64) tensor(0.1695, dtype=torch.float64)\n",
      "5510 tensor(1.4536, dtype=torch.float64) tensor(0.1668, dtype=torch.float64)\n",
      "5520 tensor(1.3157, dtype=torch.float64) tensor(0.1640, dtype=torch.float64)\n",
      "5530 tensor(1.1911, dtype=torch.float64) tensor(0.1610, dtype=torch.float64)\n",
      "5540 tensor(1.0799, dtype=torch.float64) tensor(0.1639, dtype=torch.float64)\n",
      "5550 tensor(0.9798, dtype=torch.float64) tensor(0.1687, dtype=torch.float64)\n",
      "5560 tensor(0.9866, dtype=torch.float64) tensor(0.1690, dtype=torch.float64)\n",
      "5570 tensor(0.9411, dtype=torch.float64) tensor(0.1726, dtype=torch.float64)\n",
      "5580 tensor(1.3616, dtype=torch.float64) tensor(0.1630, dtype=torch.float64)\n",
      "5590 tensor(1.2325, dtype=torch.float64) tensor(0.1647, dtype=torch.float64)\n",
      "5600 tensor(1.1161, dtype=torch.float64) tensor(0.1666, dtype=torch.float64)\n",
      "5610 tensor(1.0116, dtype=torch.float64) tensor(0.1690, dtype=torch.float64)\n",
      "5620 tensor(0.9417, dtype=torch.float64) tensor(0.1739, dtype=torch.float64)\n",
      "5630 tensor(0.9832, dtype=torch.float64) tensor(0.1699, dtype=torch.float64)\n",
      "5640 tensor(0.9564, dtype=torch.float64) tensor(0.1711, dtype=torch.float64)\n",
      "5650 tensor(1.0443, dtype=torch.float64) tensor(0.1681, dtype=torch.float64)\n",
      "5660 tensor(0.9496, dtype=torch.float64) tensor(0.1716, dtype=torch.float64)\n",
      "5670 tensor(0.9841, dtype=torch.float64) tensor(0.1684, dtype=torch.float64)\n",
      "5680 tensor(0.9463, dtype=torch.float64) tensor(0.1754, dtype=torch.float64)\n",
      "5690 tensor(3.4871, dtype=torch.float64) tensor(0.1567, dtype=torch.float64)\n",
      "5700 tensor(3.1548, dtype=torch.float64) tensor(0.1584, dtype=torch.float64)\n",
      "5710 tensor(2.8542, dtype=torch.float64) tensor(0.1600, dtype=torch.float64)\n",
      "5720 tensor(2.5823, dtype=torch.float64) tensor(0.1616, dtype=torch.float64)\n",
      "5730 tensor(2.3363, dtype=torch.float64) tensor(0.1631, dtype=torch.float64)\n",
      "5740 tensor(2.1138, dtype=torch.float64) tensor(0.1647, dtype=torch.float64)\n",
      "5750 tensor(1.9126, dtype=torch.float64) tensor(0.1662, dtype=torch.float64)\n",
      "5760 tensor(1.7306, dtype=torch.float64) tensor(0.1677, dtype=torch.float64)\n",
      "5770 tensor(1.5660, dtype=torch.float64) tensor(0.1692, dtype=torch.float64)\n",
      "5780 tensor(1.4172, dtype=torch.float64) tensor(0.1707, dtype=torch.float64)\n",
      "5790 tensor(1.2828, dtype=torch.float64) tensor(0.1723, dtype=torch.float64)\n",
      "5800 tensor(1.1613, dtype=torch.float64) tensor(0.1741, dtype=torch.float64)\n",
      "5810 tensor(1.0519, dtype=torch.float64) tensor(0.1761, dtype=torch.float64)\n",
      "5820 tensor(0.9549, dtype=torch.float64) tensor(0.1791, dtype=torch.float64)\n",
      "5830 tensor(0.9997, dtype=torch.float64) tensor(0.1775, dtype=torch.float64)\n",
      "5840 tensor(0.9306, dtype=torch.float64) tensor(0.1823, dtype=torch.float64)\n",
      "5850 tensor(0.9377, dtype=torch.float64) tensor(0.1801, dtype=torch.float64)\n",
      "5860 tensor(0.9442, dtype=torch.float64) tensor(0.1835, dtype=torch.float64)\n",
      "5870 tensor(1.0215, dtype=torch.float64) tensor(0.1769, dtype=torch.float64)\n",
      "5880 tensor(0.9310, dtype=torch.float64) tensor(0.1808, dtype=torch.float64)\n",
      "5890 tensor(0.9291, dtype=torch.float64) tensor(0.1820, dtype=torch.float64)\n",
      "5900 tensor(0.9672, dtype=torch.float64) tensor(0.1847, dtype=torch.float64)\n",
      "5910 tensor(19.0879, dtype=torch.float64) tensor(0.1867, dtype=torch.float64)\n",
      "5920 tensor(17.2674, dtype=torch.float64) tensor(0.1833, dtype=torch.float64)\n",
      "5930 tensor(15.6205, dtype=torch.float64) tensor(0.1801, dtype=torch.float64)\n",
      "5940 tensor(14.1307, dtype=torch.float64) tensor(0.1770, dtype=torch.float64)\n",
      "5950 tensor(12.7830, dtype=torch.float64) tensor(0.1740, dtype=torch.float64)\n",
      "5960 tensor(11.5639, dtype=torch.float64) tensor(0.1712, dtype=torch.float64)\n",
      "5970 tensor(10.4611, dtype=torch.float64) tensor(0.1685, dtype=torch.float64)\n",
      "5980 tensor(9.4634, dtype=torch.float64) tensor(0.1659, dtype=torch.float64)\n",
      "5990 tensor(8.5610, dtype=torch.float64) tensor(0.1634, dtype=torch.float64)\n",
      "6000 tensor(7.7446, dtype=torch.float64) tensor(0.1611, dtype=torch.float64)\n",
      "6010 tensor(7.0061, dtype=torch.float64) tensor(0.1588, dtype=torch.float64)\n",
      "6020 tensor(6.3380, dtype=torch.float64) tensor(0.1566, dtype=torch.float64)\n",
      "6030 tensor(5.7337, dtype=torch.float64) tensor(0.1545, dtype=torch.float64)\n",
      "6040 tensor(5.1870, dtype=torch.float64) tensor(0.1525, dtype=torch.float64)\n",
      "6050 tensor(4.6925, dtype=torch.float64) tensor(0.1514, dtype=torch.float64)\n",
      "6060 tensor(4.2452, dtype=torch.float64) tensor(0.1533, dtype=torch.float64)\n",
      "6070 tensor(3.8405, dtype=torch.float64) tensor(0.1551, dtype=torch.float64)\n",
      "6080 tensor(3.4745, dtype=torch.float64) tensor(0.1568, dtype=torch.float64)\n",
      "6090 tensor(3.1434, dtype=torch.float64) tensor(0.1585, dtype=torch.float64)\n",
      "6100 tensor(2.8438, dtype=torch.float64) tensor(0.1601, dtype=torch.float64)\n",
      "6110 tensor(2.5729, dtype=torch.float64) tensor(0.1617, dtype=torch.float64)\n",
      "6120 tensor(2.3278, dtype=torch.float64) tensor(0.1632, dtype=torch.float64)\n",
      "6130 tensor(2.1062, dtype=torch.float64) tensor(0.1647, dtype=torch.float64)\n",
      "6140 tensor(1.9057, dtype=torch.float64) tensor(0.1662, dtype=torch.float64)\n",
      "6150 tensor(1.7243, dtype=torch.float64) tensor(0.1677, dtype=torch.float64)\n",
      "6160 tensor(1.5604, dtype=torch.float64) tensor(0.1692, dtype=torch.float64)\n",
      "6170 tensor(1.4121, dtype=torch.float64) tensor(0.1708, dtype=torch.float64)\n",
      "6180 tensor(1.2781, dtype=torch.float64) tensor(0.1724, dtype=torch.float64)\n",
      "6190 tensor(1.1571, dtype=torch.float64) tensor(0.1742, dtype=torch.float64)\n",
      "6200 tensor(1.0482, dtype=torch.float64) tensor(0.1762, dtype=torch.float64)\n",
      "6210 tensor(0.9517, dtype=torch.float64) tensor(0.1792, dtype=torch.float64)\n",
      "6220 tensor(0.9435, dtype=torch.float64) tensor(0.1835, dtype=torch.float64)\n",
      "6230 tensor(1.0289, dtype=torch.float64) tensor(0.1767, dtype=torch.float64)\n",
      "6240 tensor(0.9361, dtype=torch.float64) tensor(0.1803, dtype=torch.float64)\n",
      "6250 tensor(32.7478, dtype=torch.float64) tensor(0.2082, dtype=torch.float64)\n",
      "6260 tensor(29.6243, dtype=torch.float64) tensor(0.2038, dtype=torch.float64)\n",
      "6270 tensor(26.7987, dtype=torch.float64) tensor(0.1996, dtype=torch.float64)\n",
      "6280 tensor(24.2426, dtype=torch.float64) tensor(0.1955, dtype=torch.float64)\n",
      "6290 tensor(21.9303, dtype=torch.float64) tensor(0.1917, dtype=torch.float64)\n",
      "6300 tensor(19.8386, dtype=torch.float64) tensor(0.1881, dtype=torch.float64)\n",
      "6310 tensor(17.9465, dtype=torch.float64) tensor(0.1846, dtype=torch.float64)\n",
      "6320 tensor(16.2348, dtype=torch.float64) tensor(0.1813, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6330 tensor(14.6864, dtype=torch.float64) tensor(0.1781, dtype=torch.float64)\n",
      "6340 tensor(13.2857, dtype=torch.float64) tensor(0.1751, dtype=torch.float64)\n",
      "6350 tensor(12.0186, dtype=torch.float64) tensor(0.1722, dtype=torch.float64)\n",
      "6360 tensor(10.8724, dtype=torch.float64) tensor(0.1695, dtype=torch.float64)\n",
      "6370 tensor(9.8356, dtype=torch.float64) tensor(0.1669, dtype=torch.float64)\n",
      "6380 tensor(8.8976, dtype=torch.float64) tensor(0.1644, dtype=torch.float64)\n",
      "6390 tensor(8.0491, dtype=torch.float64) tensor(0.1620, dtype=torch.float64)\n",
      "6400 tensor(7.2816, dtype=torch.float64) tensor(0.1597, dtype=torch.float64)\n",
      "6410 tensor(6.5872, dtype=torch.float64) tensor(0.1574, dtype=torch.float64)\n",
      "6420 tensor(5.9591, dtype=torch.float64) tensor(0.1553, dtype=torch.float64)\n",
      "6430 tensor(5.3910, dtype=torch.float64) tensor(0.1533, dtype=torch.float64)\n",
      "6440 tensor(4.8770, dtype=torch.float64) tensor(0.1514, dtype=torch.float64)\n",
      "6450 tensor(4.4121, dtype=torch.float64) tensor(0.1526, dtype=torch.float64)\n",
      "6460 tensor(3.9915, dtype=torch.float64) tensor(0.1544, dtype=torch.float64)\n",
      "6470 tensor(3.6110, dtype=torch.float64) tensor(0.1561, dtype=torch.float64)\n",
      "6480 tensor(3.2669, dtype=torch.float64) tensor(0.1578, dtype=torch.float64)\n",
      "6490 tensor(2.9556, dtype=torch.float64) tensor(0.1595, dtype=torch.float64)\n",
      "6500 tensor(2.6740, dtype=torch.float64) tensor(0.1610, dtype=torch.float64)\n",
      "6510 tensor(2.4192, dtype=torch.float64) tensor(0.1626, dtype=torch.float64)\n",
      "6520 tensor(2.1888, dtype=torch.float64) tensor(0.1641, dtype=torch.float64)\n",
      "6530 tensor(1.9805, dtype=torch.float64) tensor(0.1656, dtype=torch.float64)\n",
      "6540 tensor(1.7920, dtype=torch.float64) tensor(0.1671, dtype=torch.float64)\n",
      "6550 tensor(1.6215, dtype=torch.float64) tensor(0.1687, dtype=torch.float64)\n",
      "6560 tensor(1.4674, dtype=torch.float64) tensor(0.1702, dtype=torch.float64)\n",
      "6570 tensor(1.3281, dtype=torch.float64) tensor(0.1718, dtype=torch.float64)\n",
      "6580 tensor(1.2022, dtype=torch.float64) tensor(0.1735, dtype=torch.float64)\n",
      "6590 tensor(1.0887, dtype=torch.float64) tensor(0.1754, dtype=torch.float64)\n",
      "6600 tensor(0.9871, dtype=torch.float64) tensor(0.1778, dtype=torch.float64)\n",
      "6610 tensor(1.0470, dtype=torch.float64) tensor(0.1869, dtype=torch.float64)\n",
      "6620 tensor(0.9507, dtype=torch.float64) tensor(0.1839, dtype=torch.float64)\n",
      "6630 tensor(0.9581, dtype=torch.float64) tensor(0.1789, dtype=torch.float64)\n",
      "6640 tensor(1.0544, dtype=torch.float64) tensor(0.1837, dtype=torch.float64)\n",
      "6650 tensor(0.9566, dtype=torch.float64) tensor(0.1864, dtype=torch.float64)\n",
      "6660 tensor(1.0307, dtype=torch.float64) tensor(0.1842, dtype=torch.float64)\n",
      "6670 tensor(0.9364, dtype=torch.float64) tensor(0.1874, dtype=torch.float64)\n",
      "6680 tensor(0.9284, dtype=torch.float64) tensor(0.1879, dtype=torch.float64)\n",
      "6690 tensor(1.1252, dtype=torch.float64) tensor(0.1901, dtype=torch.float64)\n",
      "6700 tensor(1.0193, dtype=torch.float64) tensor(0.1921, dtype=torch.float64)\n",
      "6710 tensor(0.9261, dtype=torch.float64) tensor(0.1953, dtype=torch.float64)\n",
      "6720 tensor(0.9325, dtype=torch.float64) tensor(0.1950, dtype=torch.float64)\n",
      "6730 tensor(0.9111, dtype=torch.float64) tensor(0.1969, dtype=torch.float64)\n",
      "6740 tensor(1.4899, dtype=torch.float64) tensor(0.1854, dtype=torch.float64)\n",
      "6750 tensor(1.3484, dtype=torch.float64) tensor(0.1870, dtype=torch.float64)\n",
      "6760 tensor(1.2205, dtype=torch.float64) tensor(0.1886, dtype=torch.float64)\n",
      "6770 tensor(1.1051, dtype=torch.float64) tensor(0.1904, dtype=torch.float64)\n",
      "6780 tensor(1.0013, dtype=torch.float64) tensor(0.1926, dtype=torch.float64)\n",
      "6790 tensor(0.9127, dtype=torch.float64) tensor(0.1965, dtype=torch.float64)\n",
      "6800 tensor(0.9500, dtype=torch.float64) tensor(0.2004, dtype=torch.float64)\n",
      "6810 tensor(0.9263, dtype=torch.float64) tensor(0.1953, dtype=torch.float64)\n",
      "6820 tensor(1.0763, dtype=torch.float64) tensor(0.2036, dtype=torch.float64)\n",
      "6830 tensor(0.9756, dtype=torch.float64) tensor(0.2012, dtype=torch.float64)\n",
      "6840 tensor(20.2116, dtype=torch.float64) tensor(0.2894, dtype=torch.float64)\n",
      "6850 tensor(18.2839, dtype=torch.float64) tensor(0.2833, dtype=torch.float64)\n",
      "6860 tensor(16.5400, dtype=torch.float64) tensor(0.2776, dtype=torch.float64)\n",
      "6870 tensor(14.9625, dtype=torch.float64) tensor(0.2721, dtype=torch.float64)\n",
      "6880 tensor(13.5355, dtype=torch.float64) tensor(0.2668, dtype=torch.float64)\n",
      "6890 tensor(12.2446, dtype=torch.float64) tensor(0.2618, dtype=torch.float64)\n",
      "6900 tensor(11.0768, dtype=torch.float64) tensor(0.2570, dtype=torch.float64)\n",
      "6910 tensor(10.0204, dtype=torch.float64) tensor(0.2524, dtype=torch.float64)\n",
      "6920 tensor(9.0648, dtype=torch.float64) tensor(0.2480, dtype=torch.float64)\n",
      "6930 tensor(8.2004, dtype=torch.float64) tensor(0.2438, dtype=torch.float64)\n",
      "6940 tensor(7.4184, dtype=torch.float64) tensor(0.2398, dtype=torch.float64)\n",
      "6950 tensor(6.7110, dtype=torch.float64) tensor(0.2360, dtype=torch.float64)\n",
      "6960 tensor(6.0711, dtype=torch.float64) tensor(0.2323, dtype=torch.float64)\n",
      "6970 tensor(5.4922, dtype=torch.float64) tensor(0.2288, dtype=torch.float64)\n",
      "6980 tensor(4.9686, dtype=torch.float64) tensor(0.2254, dtype=torch.float64)\n",
      "6990 tensor(4.4949, dtype=torch.float64) tensor(0.2221, dtype=torch.float64)\n",
      "7000 tensor(4.0664, dtype=torch.float64) tensor(0.2190, dtype=torch.float64)\n",
      "7010 tensor(3.6788, dtype=torch.float64) tensor(0.2160, dtype=torch.float64)\n",
      "7020 tensor(3.3282, dtype=torch.float64) tensor(0.2130, dtype=torch.float64)\n",
      "7030 tensor(3.0110, dtype=torch.float64) tensor(0.2102, dtype=torch.float64)\n",
      "7040 tensor(2.7241, dtype=torch.float64) tensor(0.2074, dtype=torch.float64)\n",
      "7050 tensor(2.4646, dtype=torch.float64) tensor(0.2047, dtype=torch.float64)\n",
      "7060 tensor(2.2299, dtype=torch.float64) tensor(0.2021, dtype=torch.float64)\n",
      "7070 tensor(2.0175, dtype=torch.float64) tensor(0.1995, dtype=torch.float64)\n",
      "7080 tensor(1.8255, dtype=torch.float64) tensor(0.1969, dtype=torch.float64)\n",
      "7090 tensor(1.6518, dtype=torch.float64) tensor(0.1944, dtype=torch.float64)\n",
      "7100 tensor(1.4948, dtype=torch.float64) tensor(0.1918, dtype=torch.float64)\n",
      "7110 tensor(1.3528, dtype=torch.float64) tensor(0.1891, dtype=torch.float64)\n",
      "7120 tensor(1.2245, dtype=torch.float64) tensor(0.1863, dtype=torch.float64)\n",
      "7130 tensor(1.1092, dtype=torch.float64) tensor(0.1851, dtype=torch.float64)\n",
      "7140 tensor(1.0056, dtype=torch.float64) tensor(0.1889, dtype=torch.float64)\n",
      "7150 tensor(0.9168, dtype=torch.float64) tensor(0.1958, dtype=torch.float64)\n",
      "7160 tensor(0.9197, dtype=torch.float64) tensor(0.1946, dtype=torch.float64)\n",
      "7170 tensor(1.4977, dtype=torch.float64) tensor(0.1845, dtype=torch.float64)\n",
      "7180 tensor(1.3554, dtype=torch.float64) tensor(0.1860, dtype=torch.float64)\n",
      "7190 tensor(1.2269, dtype=torch.float64) tensor(0.1877, dtype=torch.float64)\n",
      "7200 tensor(1.1108, dtype=torch.float64) tensor(0.1895, dtype=torch.float64)\n",
      "7210 tensor(1.0065, dtype=torch.float64) tensor(0.1916, dtype=torch.float64)\n",
      "7220 tensor(0.9164, dtype=torch.float64) tensor(0.1953, dtype=torch.float64)\n",
      "7230 tensor(0.9115, dtype=torch.float64) tensor(0.1964, dtype=torch.float64)\n",
      "7240 tensor(0.9289, dtype=torch.float64) tensor(0.1950, dtype=torch.float64)\n",
      "7250 tensor(2.0558, dtype=torch.float64) tensor(0.1881, dtype=torch.float64)\n",
      "7260 tensor(1.8601, dtype=torch.float64) tensor(0.1896, dtype=torch.float64)\n",
      "7270 tensor(1.6831, dtype=torch.float64) tensor(0.1911, dtype=torch.float64)\n",
      "7280 tensor(1.5230, dtype=torch.float64) tensor(0.1926, dtype=torch.float64)\n",
      "7290 tensor(1.3783, dtype=torch.float64) tensor(0.1941, dtype=torch.float64)\n",
      "7300 tensor(1.2475, dtype=torch.float64) tensor(0.1957, dtype=torch.float64)\n",
      "7310 tensor(1.1294, dtype=torch.float64) tensor(0.1974, dtype=torch.float64)\n",
      "7320 tensor(1.0230, dtype=torch.float64) tensor(0.1994, dtype=torch.float64)\n",
      "7330 tensor(0.9286, dtype=torch.float64) tensor(0.2023, dtype=torch.float64)\n",
      "7340 tensor(0.9050, dtype=torch.float64) tensor(0.2039, dtype=torch.float64)\n",
      "7350 tensor(0.9134, dtype=torch.float64) tensor(0.2066, dtype=torch.float64)\n",
      "7360 tensor(52.3486, dtype=torch.float64) tensor(0.2560, dtype=torch.float64)\n",
      "7370 tensor(47.3553, dtype=torch.float64) tensor(0.2505, dtype=torch.float64)\n",
      "7380 tensor(42.8383, dtype=torch.float64) tensor(0.2452, dtype=torch.float64)\n",
      "7390 tensor(38.7522, dtype=torch.float64) tensor(0.2402, dtype=torch.float64)\n",
      "7400 tensor(35.0559, dtype=torch.float64) tensor(0.2354, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7410 tensor(31.7122, dtype=torch.float64) tensor(0.2308, dtype=torch.float64)\n",
      "7420 tensor(28.6874, dtype=torch.float64) tensor(0.2265, dtype=torch.float64)\n",
      "7430 tensor(25.9511, dtype=torch.float64) tensor(0.2223, dtype=torch.float64)\n",
      "7440 tensor(23.4759, dtype=torch.float64) tensor(0.2184, dtype=torch.float64)\n",
      "7450 tensor(21.2367, dtype=torch.float64) tensor(0.2146, dtype=torch.float64)\n",
      "7460 tensor(19.2112, dtype=torch.float64) tensor(0.2110, dtype=torch.float64)\n",
      "7470 tensor(17.3789, dtype=torch.float64) tensor(0.2076, dtype=torch.float64)\n",
      "7480 tensor(15.7214, dtype=torch.float64) tensor(0.2044, dtype=torch.float64)\n",
      "7490 tensor(14.2219, dtype=torch.float64) tensor(0.2013, dtype=torch.float64)\n",
      "7500 tensor(12.8655, dtype=torch.float64) tensor(0.1983, dtype=torch.float64)\n",
      "7510 tensor(11.6385, dtype=torch.float64) tensor(0.1955, dtype=torch.float64)\n",
      "7520 tensor(10.5286, dtype=torch.float64) tensor(0.1927, dtype=torch.float64)\n",
      "7530 tensor(9.5245, dtype=torch.float64) tensor(0.1902, dtype=torch.float64)\n",
      "7540 tensor(8.6162, dtype=torch.float64) tensor(0.1877, dtype=torch.float64)\n",
      "7550 tensor(7.7945, dtype=torch.float64) tensor(0.1853, dtype=torch.float64)\n",
      "7560 tensor(7.0513, dtype=torch.float64) tensor(0.1831, dtype=torch.float64)\n",
      "7570 tensor(6.3789, dtype=torch.float64) tensor(0.1809, dtype=torch.float64)\n",
      "7580 tensor(5.7707, dtype=torch.float64) tensor(0.1788, dtype=torch.float64)\n",
      "7590 tensor(5.2205, dtype=torch.float64) tensor(0.1768, dtype=torch.float64)\n",
      "7600 tensor(4.7228, dtype=torch.float64) tensor(0.1749, dtype=torch.float64)\n",
      "7610 tensor(4.2725, dtype=torch.float64) tensor(0.1763, dtype=torch.float64)\n",
      "7620 tensor(3.8652, dtype=torch.float64) tensor(0.1781, dtype=torch.float64)\n",
      "7630 tensor(3.4968, dtype=torch.float64) tensor(0.1798, dtype=torch.float64)\n",
      "7640 tensor(3.1636, dtype=torch.float64) tensor(0.1815, dtype=torch.float64)\n",
      "7650 tensor(2.8621, dtype=torch.float64) tensor(0.1831, dtype=torch.float64)\n",
      "7660 tensor(2.5894, dtype=torch.float64) tensor(0.1847, dtype=torch.float64)\n",
      "7670 tensor(2.3427, dtype=torch.float64) tensor(0.1862, dtype=torch.float64)\n",
      "7680 tensor(2.1196, dtype=torch.float64) tensor(0.1877, dtype=torch.float64)\n",
      "7690 tensor(1.9178, dtype=torch.float64) tensor(0.1892, dtype=torch.float64)\n",
      "7700 tensor(1.7353, dtype=torch.float64) tensor(0.1907, dtype=torch.float64)\n",
      "7710 tensor(1.5703, dtype=torch.float64) tensor(0.1921, dtype=torch.float64)\n",
      "7720 tensor(1.4210, dtype=torch.float64) tensor(0.1936, dtype=torch.float64)\n",
      "7730 tensor(1.2861, dtype=torch.float64) tensor(0.1952, dtype=torch.float64)\n",
      "7740 tensor(1.1642, dtype=torch.float64) tensor(0.1969, dtype=torch.float64)\n",
      "7750 tensor(1.0543, dtype=torch.float64) tensor(0.1988, dtype=torch.float64)\n",
      "7760 tensor(0.9559, dtype=torch.float64) tensor(0.2012, dtype=torch.float64)\n",
      "7770 tensor(0.9991, dtype=torch.float64) tensor(0.2000, dtype=torch.float64)\n",
      "7780 tensor(0.9089, dtype=torch.float64) tensor(0.2035, dtype=torch.float64)\n",
      "7790 tensor(15.0106, dtype=torch.float64) tensor(0.2029, dtype=torch.float64)\n",
      "7800 tensor(13.5789, dtype=torch.float64) tensor(0.1999, dtype=torch.float64)\n",
      "7810 tensor(12.2839, dtype=torch.float64) tensor(0.1970, dtype=torch.float64)\n",
      "7820 tensor(11.1124, dtype=torch.float64) tensor(0.1942, dtype=torch.float64)\n",
      "7830 tensor(10.0526, dtype=torch.float64) tensor(0.1915, dtype=torch.float64)\n",
      "7840 tensor(9.0939, dtype=torch.float64) tensor(0.1890, dtype=torch.float64)\n",
      "7850 tensor(8.2267, dtype=torch.float64) tensor(0.1866, dtype=torch.float64)\n",
      "7860 tensor(7.4422, dtype=torch.float64) tensor(0.1843, dtype=torch.float64)\n",
      "7870 tensor(6.7325, dtype=torch.float64) tensor(0.1820, dtype=torch.float64)\n",
      "7880 tensor(6.0906, dtype=torch.float64) tensor(0.1799, dtype=torch.float64)\n",
      "7890 tensor(5.5099, dtype=torch.float64) tensor(0.1779, dtype=torch.float64)\n",
      "7900 tensor(4.9845, dtype=torch.float64) tensor(0.1759, dtype=torch.float64)\n",
      "7910 tensor(4.5093, dtype=torch.float64) tensor(0.1753, dtype=torch.float64)\n",
      "7920 tensor(4.0795, dtype=torch.float64) tensor(0.1771, dtype=torch.float64)\n",
      "7930 tensor(3.6906, dtype=torch.float64) tensor(0.1789, dtype=torch.float64)\n",
      "7940 tensor(3.3388, dtype=torch.float64) tensor(0.1806, dtype=torch.float64)\n",
      "7950 tensor(3.0207, dtype=torch.float64) tensor(0.1822, dtype=torch.float64)\n",
      "7960 tensor(2.7328, dtype=torch.float64) tensor(0.1838, dtype=torch.float64)\n",
      "7970 tensor(2.4725, dtype=torch.float64) tensor(0.1854, dtype=torch.float64)\n",
      "7980 tensor(2.2370, dtype=torch.float64) tensor(0.1869, dtype=torch.float64)\n",
      "7990 tensor(2.0240, dtype=torch.float64) tensor(0.1884, dtype=torch.float64)\n",
      "8000 tensor(1.8313, dtype=torch.float64) tensor(0.1899, dtype=torch.float64)\n",
      "8010 tensor(1.6571, dtype=torch.float64) tensor(0.1913, dtype=torch.float64)\n",
      "8020 tensor(1.4995, dtype=torch.float64) tensor(0.1928, dtype=torch.float64)\n",
      "8030 tensor(1.3570, dtype=torch.float64) tensor(0.1944, dtype=torch.float64)\n",
      "8040 tensor(1.2283, dtype=torch.float64) tensor(0.1960, dtype=torch.float64)\n",
      "8050 tensor(1.1121, dtype=torch.float64) tensor(0.1977, dtype=torch.float64)\n",
      "8060 tensor(1.0075, dtype=torch.float64) tensor(0.1998, dtype=torch.float64)\n",
      "8070 tensor(0.9155, dtype=torch.float64) tensor(0.2030, dtype=torch.float64)\n",
      "8080 tensor(0.9330, dtype=torch.float64) tensor(0.2021, dtype=torch.float64)\n",
      "8090 tensor(0.9023, dtype=torch.float64) tensor(0.2053, dtype=torch.float64)\n",
      "8100 tensor(0.9026, dtype=torch.float64) tensor(0.2054, dtype=torch.float64)\n",
      "8110 tensor(0.9105, dtype=torch.float64) tensor(0.2063, dtype=torch.float64)\n",
      "8120 tensor(1.0495, dtype=torch.float64) tensor(0.2108, dtype=torch.float64)\n",
      "8130 tensor(0.9517, dtype=torch.float64) tensor(0.2083, dtype=torch.float64)\n",
      "8140 tensor(0.9176, dtype=torch.float64) tensor(0.2029, dtype=torch.float64)\n",
      "8150 tensor(1.2370, dtype=torch.float64) tensor(0.1958, dtype=torch.float64)\n",
      "8160 tensor(1.1200, dtype=torch.float64) tensor(0.1976, dtype=torch.float64)\n",
      "8170 tensor(1.0145, dtype=torch.float64) tensor(0.1996, dtype=torch.float64)\n",
      "8180 tensor(0.9214, dtype=torch.float64) tensor(0.2027, dtype=torch.float64)\n",
      "8190 tensor(4.4683, dtype=torch.float64) tensor(0.1755, dtype=torch.float64)\n",
      "8200 tensor(4.0423, dtype=torch.float64) tensor(0.1773, dtype=torch.float64)\n",
      "8210 tensor(3.6570, dtype=torch.float64) tensor(0.1790, dtype=torch.float64)\n",
      "8220 tensor(3.3084, dtype=torch.float64) tensor(0.1807, dtype=torch.float64)\n",
      "8230 tensor(2.9932, dtype=torch.float64) tensor(0.1824, dtype=torch.float64)\n",
      "8240 tensor(2.7080, dtype=torch.float64) tensor(0.1840, dtype=torch.float64)\n",
      "8250 tensor(2.4500, dtype=torch.float64) tensor(0.1855, dtype=torch.float64)\n",
      "8260 tensor(2.2166, dtype=torch.float64) tensor(0.1870, dtype=torch.float64)\n",
      "8270 tensor(2.0056, dtype=torch.float64) tensor(0.1885, dtype=torch.float64)\n",
      "8280 tensor(1.8147, dtype=torch.float64) tensor(0.1900, dtype=torch.float64)\n",
      "8290 tensor(1.6420, dtype=torch.float64) tensor(0.1915, dtype=torch.float64)\n",
      "8300 tensor(1.4859, dtype=torch.float64) tensor(0.1930, dtype=torch.float64)\n",
      "8310 tensor(1.3447, dtype=torch.float64) tensor(0.1945, dtype=torch.float64)\n",
      "8320 tensor(1.2172, dtype=torch.float64) tensor(0.1961, dtype=torch.float64)\n",
      "8330 tensor(1.1021, dtype=torch.float64) tensor(0.1979, dtype=torch.float64)\n",
      "8340 tensor(0.9985, dtype=torch.float64) tensor(0.2000, dtype=torch.float64)\n",
      "8350 tensor(0.9085, dtype=torch.float64) tensor(0.2036, dtype=torch.float64)\n",
      "8360 tensor(137.0199, dtype=torch.float64) tensor(0.3260, dtype=torch.float64)\n",
      "8370 tensor(123.9498, dtype=torch.float64) tensor(0.3170, dtype=torch.float64)\n",
      "8380 tensor(112.1265, dtype=torch.float64) tensor(0.3085, dtype=torch.float64)\n",
      "8390 tensor(101.4310, dtype=torch.float64) tensor(0.3004, dtype=torch.float64)\n",
      "8400 tensor(91.7558, dtype=torch.float64) tensor(0.2927, dtype=torch.float64)\n",
      "8410 tensor(83.0035, dtype=torch.float64) tensor(0.2854, dtype=torch.float64)\n",
      "8420 tensor(75.0860, dtype=torch.float64) tensor(0.2785, dtype=torch.float64)\n",
      "8430 tensor(67.9238, dtype=torch.float64) tensor(0.2718, dtype=torch.float64)\n",
      "8440 tensor(61.4448, dtype=torch.float64) tensor(0.2655, dtype=torch.float64)\n",
      "8450 tensor(55.5839, dtype=torch.float64) tensor(0.2595, dtype=torch.float64)\n",
      "8460 tensor(50.2820, dtype=torch.float64) tensor(0.2538, dtype=torch.float64)\n",
      "8470 tensor(45.4858, dtype=torch.float64) tensor(0.2483, dtype=torch.float64)\n",
      "8480 tensor(41.1472, dtype=torch.float64) tensor(0.2432, dtype=torch.float64)\n",
      "8490 tensor(37.2224, dtype=torch.float64) tensor(0.2382, dtype=torch.float64)\n",
      "8500 tensor(33.6720, dtype=torch.float64) tensor(0.2335, dtype=torch.float64)\n",
      "8510 tensor(30.4602, dtype=torch.float64) tensor(0.2291, dtype=torch.float64)\n",
      "8520 tensor(27.5549, dtype=torch.float64) tensor(0.2248, dtype=torch.float64)\n",
      "8530 tensor(24.9266, dtype=torch.float64) tensor(0.2207, dtype=torch.float64)\n",
      "8540 tensor(22.5491, dtype=torch.float64) tensor(0.2169, dtype=torch.float64)\n",
      "8550 tensor(20.3984, dtype=torch.float64) tensor(0.2132, dtype=torch.float64)\n",
      "8560 tensor(18.4528, dtype=torch.float64) tensor(0.2096, dtype=torch.float64)\n",
      "8570 tensor(16.6929, dtype=torch.float64) tensor(0.2063, dtype=torch.float64)\n",
      "8580 tensor(15.1008, dtype=torch.float64) tensor(0.2031, dtype=torch.float64)\n",
      "8590 tensor(13.6605, dtype=torch.float64) tensor(0.2000, dtype=torch.float64)\n",
      "8600 tensor(12.3577, dtype=torch.float64) tensor(0.1971, dtype=torch.float64)\n",
      "8610 tensor(11.1791, dtype=torch.float64) tensor(0.1944, dtype=torch.float64)\n",
      "8620 tensor(10.1130, dtype=torch.float64) tensor(0.1917, dtype=torch.float64)\n",
      "8630 tensor(9.1486, dtype=torch.float64) tensor(0.1892, dtype=torch.float64)\n",
      "8640 tensor(8.2761, dtype=torch.float64) tensor(0.1867, dtype=torch.float64)\n",
      "8650 tensor(7.4869, dtype=torch.float64) tensor(0.1844, dtype=torch.float64)\n",
      "8660 tensor(6.7730, dtype=torch.float64) tensor(0.1822, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8670 tensor(6.1272, dtype=torch.float64) tensor(0.1800, dtype=torch.float64)\n",
      "8680 tensor(5.5430, dtype=torch.float64) tensor(0.1780, dtype=torch.float64)\n",
      "8690 tensor(5.0145, dtype=torch.float64) tensor(0.1760, dtype=torch.float64)\n",
      "8700 tensor(4.5364, dtype=torch.float64) tensor(0.1752, dtype=torch.float64)\n",
      "8710 tensor(4.1040, dtype=torch.float64) tensor(0.1770, dtype=torch.float64)\n",
      "8720 tensor(3.7128, dtype=torch.float64) tensor(0.1788, dtype=torch.float64)\n",
      "8730 tensor(3.3589, dtype=torch.float64) tensor(0.1805, dtype=torch.float64)\n",
      "8740 tensor(3.0388, dtype=torch.float64) tensor(0.1821, dtype=torch.float64)\n",
      "8750 tensor(2.7492, dtype=torch.float64) tensor(0.1837, dtype=torch.float64)\n",
      "8760 tensor(2.4873, dtype=torch.float64) tensor(0.1853, dtype=torch.float64)\n",
      "8770 tensor(2.2504, dtype=torch.float64) tensor(0.1868, dtype=torch.float64)\n",
      "8780 tensor(2.0361, dtype=torch.float64) tensor(0.1883, dtype=torch.float64)\n",
      "8790 tensor(1.8423, dtype=torch.float64) tensor(0.1898, dtype=torch.float64)\n",
      "8800 tensor(1.6670, dtype=torch.float64) tensor(0.1913, dtype=torch.float64)\n",
      "8810 tensor(1.5085, dtype=torch.float64) tensor(0.1927, dtype=torch.float64)\n",
      "8820 tensor(1.3652, dtype=torch.float64) tensor(0.1943, dtype=torch.float64)\n",
      "8830 tensor(1.2356, dtype=torch.float64) tensor(0.1959, dtype=torch.float64)\n",
      "8840 tensor(1.1187, dtype=torch.float64) tensor(0.1976, dtype=torch.float64)\n",
      "8850 tensor(1.0134, dtype=torch.float64) tensor(0.1997, dtype=torch.float64)\n",
      "8860 tensor(0.9204, dtype=torch.float64) tensor(0.2027, dtype=torch.float64)\n",
      "8870 tensor(0.9304, dtype=torch.float64) tensor(0.2022, dtype=torch.float64)\n",
      "8880 tensor(1.2002, dtype=torch.float64) tensor(0.2041, dtype=torch.float64)\n",
      "8890 tensor(1.0867, dtype=torch.float64) tensor(0.2059, dtype=torch.float64)\n",
      "8900 tensor(0.9846, dtype=torch.float64) tensor(0.2080, dtype=torch.float64)\n",
      "8910 tensor(0.8967, dtype=torch.float64) tensor(0.2118, dtype=torch.float64)\n",
      "8920 tensor(1.2044, dtype=torch.float64) tensor(0.2041, dtype=torch.float64)\n",
      "8930 tensor(1.0905, dtype=torch.float64) tensor(0.2058, dtype=torch.float64)\n",
      "8940 tensor(0.9880, dtype=torch.float64) tensor(0.2080, dtype=torch.float64)\n",
      "8950 tensor(0.8991, dtype=torch.float64) tensor(0.2115, dtype=torch.float64)\n",
      "8960 tensor(0.9041, dtype=torch.float64) tensor(0.2111, dtype=torch.float64)\n",
      "8970 tensor(2.0333, dtype=torch.float64) tensor(0.1961, dtype=torch.float64)\n",
      "8980 tensor(1.8398, dtype=torch.float64) tensor(0.1976, dtype=torch.float64)\n",
      "8990 tensor(1.6647, dtype=torch.float64) tensor(0.1991, dtype=torch.float64)\n",
      "9000 tensor(1.5064, dtype=torch.float64) tensor(0.2006, dtype=torch.float64)\n",
      "9010 tensor(1.3633, dtype=torch.float64) tensor(0.2021, dtype=torch.float64)\n",
      "9020 tensor(1.2339, dtype=torch.float64) tensor(0.2037, dtype=torch.float64)\n",
      "9030 tensor(1.1171, dtype=torch.float64) tensor(0.2054, dtype=torch.float64)\n",
      "9040 tensor(1.0119, dtype=torch.float64) tensor(0.2074, dtype=torch.float64)\n",
      "9050 tensor(0.9185, dtype=torch.float64) tensor(0.2103, dtype=torch.float64)\n",
      "9060 tensor(0.8934, dtype=torch.float64) tensor(0.2123, dtype=torch.float64)\n",
      "9070 tensor(0.9610, dtype=torch.float64) tensor(0.2168, dtype=torch.float64)\n",
      "9080 tensor(0.8941, dtype=torch.float64) tensor(0.2122, dtype=torch.float64)\n",
      "9090 tensor(0.8939, dtype=torch.float64) tensor(0.2133, dtype=torch.float64)\n",
      "9100 tensor(20.9937, dtype=torch.float64) tensor(0.3079, dtype=torch.float64)\n",
      "9110 tensor(18.9914, dtype=torch.float64) tensor(0.3018, dtype=torch.float64)\n",
      "9120 tensor(17.1800, dtype=torch.float64) tensor(0.2959, dtype=torch.float64)\n",
      "9130 tensor(15.5414, dtype=torch.float64) tensor(0.2903, dtype=torch.float64)\n",
      "9140 tensor(14.0592, dtype=torch.float64) tensor(0.2850, dtype=torch.float64)\n",
      "9150 tensor(12.7183, dtype=torch.float64) tensor(0.2798, dtype=torch.float64)\n",
      "9160 tensor(11.5053, dtype=torch.float64) tensor(0.2750, dtype=torch.float64)\n",
      "9170 tensor(10.4081, dtype=torch.float64) tensor(0.2703, dtype=torch.float64)\n",
      "9180 tensor(9.4155, dtype=torch.float64) tensor(0.2659, dtype=torch.float64)\n",
      "9190 tensor(8.5176, dtype=torch.float64) tensor(0.2616, dtype=torch.float64)\n",
      "9200 tensor(7.7053, dtype=torch.float64) tensor(0.2576, dtype=torch.float64)\n",
      "9210 tensor(6.9706, dtype=torch.float64) tensor(0.2537, dtype=torch.float64)\n",
      "9220 tensor(6.3059, dtype=torch.float64) tensor(0.2499, dtype=torch.float64)\n",
      "9230 tensor(5.7046, dtype=torch.float64) tensor(0.2463, dtype=torch.float64)\n",
      "9240 tensor(5.1607, dtype=torch.float64) tensor(0.2429, dtype=torch.float64)\n",
      "9250 tensor(4.6687, dtype=torch.float64) tensor(0.2396, dtype=torch.float64)\n",
      "9260 tensor(4.2236, dtype=torch.float64) tensor(0.2364, dtype=torch.float64)\n",
      "9270 tensor(3.8210, dtype=torch.float64) tensor(0.2334, dtype=torch.float64)\n",
      "9280 tensor(3.4568, dtype=torch.float64) tensor(0.2304, dtype=torch.float64)\n",
      "9290 tensor(3.1274, dtype=torch.float64) tensor(0.2276, dtype=torch.float64)\n",
      "9300 tensor(2.8294, dtype=torch.float64) tensor(0.2248, dtype=torch.float64)\n",
      "9310 tensor(2.5598, dtype=torch.float64) tensor(0.2221, dtype=torch.float64)\n",
      "9320 tensor(2.3159, dtype=torch.float64) tensor(0.2194, dtype=torch.float64)\n",
      "9330 tensor(2.0954, dtype=torch.float64) tensor(0.2168, dtype=torch.float64)\n",
      "9340 tensor(1.8959, dtype=torch.float64) tensor(0.2143, dtype=torch.float64)\n",
      "9350 tensor(1.7155, dtype=torch.float64) tensor(0.2117, dtype=torch.float64)\n",
      "9360 tensor(1.5523, dtype=torch.float64) tensor(0.2092, dtype=torch.float64)\n",
      "9370 tensor(1.4048, dtype=torch.float64) tensor(0.2066, dtype=torch.float64)\n",
      "9380 tensor(1.2714, dtype=torch.float64) tensor(0.2039, dtype=torch.float64)\n",
      "9390 tensor(1.1509, dtype=torch.float64) tensor(0.2010, dtype=torch.float64)\n",
      "9400 tensor(1.0435, dtype=torch.float64) tensor(0.2022, dtype=torch.float64)\n",
      "9410 tensor(0.9462, dtype=torch.float64) tensor(0.2065, dtype=torch.float64)\n",
      "9420 tensor(1.6418, dtype=torch.float64) tensor(0.1988, dtype=torch.float64)\n",
      "9430 tensor(1.4856, dtype=torch.float64) tensor(0.2003, dtype=torch.float64)\n",
      "9440 tensor(1.3445, dtype=torch.float64) tensor(0.2018, dtype=torch.float64)\n",
      "9450 tensor(1.2170, dtype=torch.float64) tensor(0.2034, dtype=torch.float64)\n",
      "9460 tensor(1.1018, dtype=torch.float64) tensor(0.2052, dtype=torch.float64)\n",
      "9470 tensor(0.9981, dtype=torch.float64) tensor(0.2072, dtype=torch.float64)\n",
      "9480 tensor(0.9070, dtype=torch.float64) tensor(0.2104, dtype=torch.float64)\n",
      "9490 tensor(0.8944, dtype=torch.float64) tensor(0.2117, dtype=torch.float64)\n",
      "9500 tensor(0.9018, dtype=torch.float64) tensor(0.2108, dtype=torch.float64)\n",
      "9510 tensor(0.9014, dtype=torch.float64) tensor(0.2137, dtype=torch.float64)\n",
      "9520 tensor(1.2465, dtype=torch.float64) tensor(0.2030, dtype=torch.float64)\n",
      "9530 tensor(1.1284, dtype=torch.float64) tensor(0.2047, dtype=torch.float64)\n",
      "9540 tensor(1.0221, dtype=torch.float64) tensor(0.2067, dtype=torch.float64)\n",
      "9550 tensor(0.9273, dtype=torch.float64) tensor(0.2094, dtype=torch.float64)\n",
      "9560 tensor(0.9032, dtype=torch.float64) tensor(0.2139, dtype=torch.float64)\n",
      "9570 tensor(0.9274, dtype=torch.float64) tensor(0.2152, dtype=torch.float64)\n",
      "9580 tensor(0.9099, dtype=torch.float64) tensor(0.2143, dtype=torch.float64)\n",
      "9590 tensor(0.9824, dtype=torch.float64) tensor(0.2076, dtype=torch.float64)\n",
      "9600 tensor(0.8954, dtype=torch.float64) tensor(0.2115, dtype=torch.float64)\n",
      "9610 tensor(1.0361, dtype=torch.float64) tensor(0.2064, dtype=torch.float64)\n",
      "9620 tensor(0.9396, dtype=torch.float64) tensor(0.2089, dtype=torch.float64)\n",
      "9630 tensor(0.9170, dtype=torch.float64) tensor(0.2169, dtype=torch.float64)\n",
      "9640 tensor(2.0873, dtype=torch.float64) tensor(0.1950, dtype=torch.float64)\n",
      "9650 tensor(1.8886, dtype=torch.float64) tensor(0.1965, dtype=torch.float64)\n",
      "9660 tensor(1.7088, dtype=torch.float64) tensor(0.1980, dtype=torch.float64)\n",
      "9670 tensor(1.5463, dtype=torch.float64) tensor(0.1995, dtype=torch.float64)\n",
      "9680 tensor(1.3994, dtype=torch.float64) tensor(0.2010, dtype=torch.float64)\n",
      "9690 tensor(1.2665, dtype=torch.float64) tensor(0.2025, dtype=torch.float64)\n",
      "9700 tensor(1.1465, dtype=torch.float64) tensor(0.2042, dtype=torch.float64)\n",
      "9710 tensor(1.0383, dtype=torch.float64) tensor(0.2061, dtype=torch.float64)\n",
      "9720 tensor(0.9416, dtype=torch.float64) tensor(0.2086, dtype=torch.float64)\n",
      "9730 tensor(0.8935, dtype=torch.float64) tensor(0.2119, dtype=torch.float64)\n",
      "9740 tensor(0.8931, dtype=torch.float64) tensor(0.2121, dtype=torch.float64)\n",
      "9750 tensor(0.8946, dtype=torch.float64) tensor(0.2136, dtype=torch.float64)\n",
      "9760 tensor(0.9306, dtype=torch.float64) tensor(0.2100, dtype=torch.float64)\n",
      "9770 tensor(2.3395, dtype=torch.float64) tensor(0.2192, dtype=torch.float64)\n",
      "9780 tensor(2.1167, dtype=torch.float64) tensor(0.2166, dtype=torch.float64)\n",
      "9790 tensor(1.9151, dtype=torch.float64) tensor(0.2140, dtype=torch.float64)\n",
      "9800 tensor(1.7329, dtype=torch.float64) tensor(0.2115, dtype=torch.float64)\n",
      "9810 tensor(1.5680, dtype=torch.float64) tensor(0.2089, dtype=torch.float64)\n",
      "9820 tensor(1.4190, dtype=torch.float64) tensor(0.2063, dtype=torch.float64)\n",
      "9830 tensor(1.2843, dtype=torch.float64) tensor(0.2036, dtype=torch.float64)\n",
      "9840 tensor(1.1625, dtype=torch.float64) tensor(0.2008, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9850 tensor(1.0537, dtype=torch.float64) tensor(0.2018, dtype=torch.float64)\n",
      "9860 tensor(0.9553, dtype=torch.float64) tensor(0.2059, dtype=torch.float64)\n",
      "9870 tensor(0.9571, dtype=torch.float64) tensor(0.2074, dtype=torch.float64)\n",
      "9880 tensor(0.9420, dtype=torch.float64) tensor(0.2187, dtype=torch.float64)\n",
      "9890 tensor(0.8945, dtype=torch.float64) tensor(0.2126, dtype=torch.float64)\n",
      "9900 tensor(0.9927, dtype=torch.float64) tensor(0.2072, dtype=torch.float64)\n",
      "9910 tensor(0.9028, dtype=torch.float64) tensor(0.2106, dtype=torch.float64)\n",
      "9920 tensor(0.9197, dtype=torch.float64) tensor(0.2083, dtype=torch.float64)\n",
      "9930 tensor(0.8999, dtype=torch.float64) tensor(0.2112, dtype=torch.float64)\n",
      "9940 tensor(1.0287, dtype=torch.float64) tensor(0.2068, dtype=torch.float64)\n",
      "9950 tensor(0.9331, dtype=torch.float64) tensor(0.2094, dtype=torch.float64)\n",
      "9960 tensor(0.9801, dtype=torch.float64) tensor(0.2079, dtype=torch.float64)\n",
      "9970 tensor(0.8940, dtype=torch.float64) tensor(0.2119, dtype=torch.float64)\n",
      "9980 tensor(0.9617, dtype=torch.float64) tensor(0.2166, dtype=torch.float64)\n",
      "9990 tensor(0.8929, dtype=torch.float64) tensor(0.2123, dtype=torch.float64)\n",
      "10000 tensor(0.9228, dtype=torch.float64) tensor(0.2152, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Line 1\n",
    "N = 9\n",
    "a = torch.zeros(N,requires_grad=True, dtype=torch.float64)\n",
    "loss = mse(Fmodel(a, xvals), lpsa)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    a -= a.grad * 1e-5\n",
    "    a.grad.zero_()\n",
    "nu = 0\n",
    "ncount = 0\n",
    "NMAX = 10000\n",
    "\n",
    "## Line 2\n",
    "while True:\n",
    "    ## Line 3\n",
    "    R = mse(Fmodel(a, xvals), lpsa);R.backward(); g = -a.grad; a.grad.zero_() #(24)\n",
    "    P = abs(a).pow(1).sum(); P.backward(); p = abs(a.grad); a.grad.zero_() #(25)\n",
    "    l = g/p #(26)\n",
    "    ## Line 4\n",
    "    # use element wise multiplication and less than 0 predicate\n",
    "    # to find elements with corresponding opposite sign\n",
    "    S = l*a < 0\n",
    "    ## Line 5\n",
    "    # need to maintain idx location, i.e. need to keep tensor shape the same throughout\n",
    "    # torch.max() finds max element and respective index\n",
    "    if S.sum() > 0: # check for elements in set\n",
    "        # non empty case (order different than stated algorithm)\n",
    "        # S.double() for matching element types needed by PyTorch\n",
    "        # element wise mult to zero out elements not meeting predicate condition\n",
    "        # done this way to make sure idx refer to corresponding element\n",
    "        val,idx = torch.max(S.double() * l.abs(), 0)\n",
    "    else:\n",
    "        # empty case\n",
    "        val,idx = torch.max(l.abs(), 0)\n",
    "    ## Line 6\n",
    "    with torch.no_grad():\n",
    "        # recall that no gradients should be calculated here while a is being updated\n",
    "        del_nu = 0.01 * (R / g[idx]).abs()\n",
    "        a[idx] += del_nu * torch.sign(l[idx])\n",
    "        # should be 'close' to 0.01\n",
    "        # R_post = mse(Fmodel(a, xvals), lpsa); print(1-(R_post/R))\n",
    "        a.grad.zero_()\n",
    "    ## Line 7\n",
    "    nu += del_nu\n",
    "    ## Line 8\n",
    "    #print(l.sum())\n",
    "    if (ncount % 10 == 0): \n",
    "        print(ncount,R.data,P.data)\n",
    "    if (ncount > NMAX) or (l.abs().sum() <= 0):\n",
    "        break\n",
    "    ncount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0138, 0.0154, 0.0039, 0.0320, 0.0612, 0.0417, 0.0721, 0.0094, 0.0124],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0041, 0.1258, 0.0433, 0.0262, 0.0232, 0.0315, 0.0709, 0.0301, 0.0105],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9936e+00,  3.6785e+01,  8.0053e+00, -1.0236e+02,  5.3276e-02,\n",
       "         3.3120e+00,  4.3077e+00, -2.1189e+01, -1.8927e+02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
